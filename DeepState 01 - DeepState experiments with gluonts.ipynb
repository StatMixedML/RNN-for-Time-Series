{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepState - Experiments\n",
    "\n",
    "- Using DeepState with gluonts to run some experiments\n",
    "- Follow this installation guide: http://gluon-ts-staging.s3-accelerate.dualstack.amazonaws.com/PR-271/4/install.html\n",
    "\n",
    "Important note! Some of these models are not yet released in version \"0.3.3\" which is currently the most recent version on pypi from where you install packages via `pip install`. Hence, you should follow **Install from Source Code** (which I did) **Install from Github**\n",
    "\n",
    "### Deep State Space Models (Rangapuram et al., 2018)\n",
    "\n",
    "**DeepState** combines state space models (SSM) with a recurrent neural network (RNN). The SSM is applied *locally* to the individual time series that is parametrized using a *global* representation in form of a RNN. The RNN is trained on the entire dataset. \n",
    "\n",
    "- [`DeepStateEstimator`](http://gluon-ts.mxnet.io/master/api/gluonts/gluonts.model.deepstate.html#gluonts.model.deepstate.DeepStateEstimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/awslabs/gluon-ts.git\n",
      "  Cloning https://github.com/awslabs/gluon-ts.git to /tmp/pip-req-build-jkykha04\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3==1.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev68+ga894aee) (1.9.251)\n",
      "Collecting holidays==0.9.* (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/17/a452275a0b3e811a381137ff6a61649086af4c5bf2a25755f518cc64b39e/holidays-0.9.11.tar.gz (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 6.1MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev68+ga894aee) (3.0.3)\n",
      "Collecting mxnet<1.5.*,>=1.3.1 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f4/bc147a1ba7175f9890523ff8f1a928a43ac8a79d5897a067158cac4d092f/mxnet-1.4.1-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 1.9MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.14.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev68+ga894aee) (1.14.5)\n",
      "Collecting pandas>=0.25.0 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/12/08b092f6fc9e4c2552e37add0861d0e0e0d743f78f1318973caad970b3fc/pandas-0.25.2-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 8.7MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic==0.28.* (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/bc/fe7d98f0b4b1e72d0c444f343a798461c1f9d8656fb1c335416dbb8b7976/pydantic-0.28-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.8MB 16.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.23.0 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 46.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ujson>=1.35 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 61.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.251 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (1.12.251)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev68+ga894aee) (2.7.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev68+ga894aee) (1.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (0.10.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (0.8.4)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (2.20.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.25.0->gluonts==0.3.4.dev68+ga894aee) (2018.4)\n",
      "Collecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic==0.28.*->gluonts==0.3.4.dev68+ga894aee)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.251->boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (0.14)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.251->boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (1.23)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (39.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (3.0.4)\n",
      "Building wheels for collected packages: gluonts, holidays, ujson\n",
      "  Running setup.py bdist_wheel for gluonts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-6pfey60h/wheels/09/ba/b9/c830628df4d977a9dfe661f6001cdb861fc3f2524bac0ee433\n",
      "  Running setup.py bdist_wheel for holidays ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/40/a9/2b/94ac5464363d37564a87dc93a9d21a5850aac14a4608197003\n",
      "  Running setup.py bdist_wheel for ujson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "Successfully built gluonts holidays ujson\n",
      "Installing collected packages: holidays, mxnet, pandas, dataclasses, pydantic, tqdm, ujson, gluonts\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed dataclasses-0.7 gluonts-0.3.4.dev68+ga894aee holidays-0.9.11 mxnet-1.4.1 pandas-0.25.2 pydantic-0.28 tqdm-4.36.1 ujson-1.35\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "0.3.4.dev68+ga894aee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using CPU\n"
     ]
    }
   ],
   "source": [
    "# if version does not include DeepState, uncomment the following:\n",
    "!pip install git+https://github.com/awslabs/gluon-ts.git\n",
    "\n",
    "import gluonts\n",
    "print(gluonts.__version__)\n",
    "\n",
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# vis imports \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# json\n",
    "import json\n",
    "\n",
    "# gluon data \n",
    "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "# gluon imports\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "# model imports \n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "# from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "# from gluonts.model.deepar import DeepAREstimator\n",
    "\n",
    "import mxnet as mx\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_state(seed=42, data=\"m4_daily\", epochs=25, batches=50):\n",
    "    dataset = get_dataset(data)\n",
    "\n",
    "    mx.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        ctx=mx.cpu(0),\n",
    "#         ctx=mx.gpu(0),\n",
    "        epochs=epochs,\n",
    "        num_batches_per_epoch=batches,\n",
    "        learning_rate=1e-3,\n",
    "    )\n",
    "\n",
    "    cardinality = int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "    estimator = DeepStateEstimator(\n",
    "        trainer=trainer,\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "#         past_length=48,\n",
    "        use_feat_static_cat=True,\n",
    "        cardinality=[cardinality],\n",
    "    )\n",
    "\n",
    "    predictor = estimator.train(dataset.train)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "    metrics = [\"MASE\", \"sMAPE\", \"MSIS\", \"wQuantileLoss[0.5]\", \"wQuantileLoss[0.9]\"]\n",
    "    output = {key: round(value, 8) for key, value in agg_metrics.items() if key in metrics}\n",
    "    output[\"epochs\"] = epochs\n",
    "    output[\"seed\"] = seed\n",
    "\n",
    "    pprint(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloading and processing m4_monthly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_monthly/train/data.json\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_monthly/test/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepStateTrainingNetwork: 2429349\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.47it/s, avg_epoch_loss=-.253]\n",
      "INFO:root:Epoch[0] Elapsed time 105.616 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=-0.252549\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.59it/s, avg_epoch_loss=-.182] \n",
      "INFO:root:Epoch[1] Elapsed time 104.319 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=-0.182159\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:43<00:00,  9.64it/s, avg_epoch_loss=-.86]\n",
      "INFO:root:Epoch[2] Elapsed time 103.737 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=-0.860197\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.43it/s, avg_epoch_loss=-1.02]\n",
      "INFO:root:Epoch[3] Elapsed time 106.062 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=-1.021786\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.58it/s, avg_epoch_loss=-1]  \n",
      "INFO:root:Epoch[4] Elapsed time 104.427 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=-1.001496\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:43<00:00,  9.62it/s, avg_epoch_loss=-1.1]\n",
      "INFO:root:Epoch[5] Elapsed time 103.969 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=-1.103310\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.45it/s, avg_epoch_loss=-1.38]\n",
      "INFO:root:Epoch[6] Elapsed time 105.776 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=-1.384220\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:43<00:00,  9.62it/s, avg_epoch_loss=-1.15]\n",
      "INFO:root:Epoch[7] Elapsed time 103.964 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=-1.153355\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.57it/s, avg_epoch_loss=-1.25]\n",
      "INFO:root:Epoch[8] Elapsed time 104.494 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=-1.252769\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.61it/s, avg_epoch_loss=-1.52]\n",
      "INFO:root:Epoch[9] Elapsed time 104.088 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=-1.516094\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.41it/s, avg_epoch_loss=-1.24]\n",
      "INFO:root:Epoch[10] Elapsed time 106.232 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=-1.244171\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.43it/s, avg_epoch_loss=-1.35]\n",
      "INFO:root:Epoch[11] Elapsed time 105.992 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=-1.345781\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.44it/s, avg_epoch_loss=-1.62]\n",
      "INFO:root:Epoch[12] Elapsed time 105.886 seconds\n",
      "INFO:root:Epoch[12] Evaluation metric 'epoch_loss'=-1.619304\n",
      "INFO:root:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.56it/s, avg_epoch_loss=-1.36]\n",
      "INFO:root:Epoch[13] Elapsed time 104.628 seconds\n",
      "INFO:root:Epoch[13] Evaluation metric 'epoch_loss'=-1.362312\n",
      "INFO:root:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:43<00:00,  9.62it/s, avg_epoch_loss=-1.42]\n",
      "INFO:root:Epoch[14] Elapsed time 103.934 seconds\n",
      "INFO:root:Epoch[14] Evaluation metric 'epoch_loss'=-1.421311\n",
      "INFO:root:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.55it/s, avg_epoch_loss=-1.7]\n",
      "INFO:root:Epoch[15] Elapsed time 104.684 seconds\n",
      "INFO:root:Epoch[15] Evaluation metric 'epoch_loss'=-1.703905\n",
      "INFO:root:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.47it/s, avg_epoch_loss=-1.45]\n",
      "INFO:root:Epoch[16] Elapsed time 105.614 seconds\n",
      "INFO:root:Epoch[16] Evaluation metric 'epoch_loss'=-1.453558\n",
      "INFO:root:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.51it/s, avg_epoch_loss=-1.53]\n",
      "INFO:root:Epoch[17] Elapsed time 105.120 seconds\n",
      "INFO:root:Epoch[17] Evaluation metric 'epoch_loss'=-1.528090\n",
      "INFO:root:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.47it/s, avg_epoch_loss=-1.84]\n",
      "INFO:root:Epoch[18] Elapsed time 105.654 seconds\n",
      "INFO:root:Epoch[18] Evaluation metric 'epoch_loss'=-1.843113\n",
      "INFO:root:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.61it/s, avg_epoch_loss=-1.56]\n",
      "INFO:root:Epoch[19] Elapsed time 104.093 seconds\n",
      "INFO:root:Epoch[19] Evaluation metric 'epoch_loss'=-1.555586\n",
      "INFO:root:Epoch[20] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.56it/s, avg_epoch_loss=-1.61]\n",
      "INFO:root:Epoch[20] Elapsed time 104.616 seconds\n",
      "INFO:root:Epoch[20] Evaluation metric 'epoch_loss'=-1.606882\n",
      "INFO:root:Epoch[21] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.58it/s, avg_epoch_loss=-1.93]\n",
      "INFO:root:Epoch[21] Elapsed time 104.389 seconds\n",
      "INFO:root:Epoch[21] Evaluation metric 'epoch_loss'=-1.925945\n",
      "INFO:root:Epoch[22] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.42it/s, avg_epoch_loss=-1.61]\n",
      "INFO:root:Epoch[22] Elapsed time 106.206 seconds\n",
      "INFO:root:Epoch[22] Evaluation metric 'epoch_loss'=-1.612341\n",
      "INFO:root:Epoch[23] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.39it/s, avg_epoch_loss=-1.66]\n",
      "INFO:root:Epoch[23] Elapsed time 106.453 seconds\n",
      "INFO:root:Epoch[23] Evaluation metric 'epoch_loss'=-1.658366\n",
      "INFO:root:Epoch[24] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:47<00:00,  9.28it/s, avg_epoch_loss=-1.97]\n",
      "INFO:root:Epoch[24] Elapsed time 107.729 seconds\n",
      "INFO:root:Epoch[24] Evaluation metric 'epoch_loss'=-1.967551\n",
      "INFO:root:Epoch[25] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.54it/s, avg_epoch_loss=-1.65]\n",
      "INFO:root:Epoch[25] Elapsed time 104.770 seconds\n",
      "INFO:root:Epoch[25] Evaluation metric 'epoch_loss'=-1.647585\n",
      "INFO:root:Epoch[26] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.61it/s, avg_epoch_loss=-1.69]\n",
      "INFO:root:Epoch[26] Elapsed time 104.035 seconds\n",
      "INFO:root:Epoch[26] Evaluation metric 'epoch_loss'=-1.686619\n",
      "INFO:root:Epoch[27] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.52it/s, avg_epoch_loss=-2.01]\n",
      "INFO:root:Epoch[27] Elapsed time 105.013 seconds\n",
      "INFO:root:Epoch[27] Evaluation metric 'epoch_loss'=-2.010097\n",
      "INFO:root:Epoch[28] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.44it/s, avg_epoch_loss=-1.68]\n",
      "INFO:root:Epoch[28] Elapsed time 105.952 seconds\n",
      "INFO:root:Epoch[28] Evaluation metric 'epoch_loss'=-1.679806\n",
      "INFO:root:Epoch[29] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.51it/s, avg_epoch_loss=-1.72]\n",
      "INFO:root:Epoch[29] Elapsed time 105.133 seconds\n",
      "INFO:root:Epoch[29] Evaluation metric 'epoch_loss'=-1.719431\n",
      "INFO:root:Epoch[30] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.45it/s, avg_epoch_loss=-2.03]\n",
      "INFO:root:Epoch[30] Elapsed time 105.875 seconds\n",
      "INFO:root:Epoch[30] Evaluation metric 'epoch_loss'=-2.027862\n",
      "INFO:root:Epoch[31] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.61it/s, avg_epoch_loss=-1.69]\n",
      "INFO:root:Epoch[31] Elapsed time 104.061 seconds\n",
      "INFO:root:Epoch[31] Evaluation metric 'epoch_loss'=-1.691151\n",
      "INFO:root:Epoch[32] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.56it/s, avg_epoch_loss=-1.72]\n",
      "INFO:root:Epoch[32] Elapsed time 104.639 seconds\n",
      "INFO:root:Epoch[32] Evaluation metric 'epoch_loss'=-1.723268\n",
      "INFO:root:Epoch[33] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.58it/s, avg_epoch_loss=-2.03]\n",
      "INFO:root:Epoch[33] Elapsed time 104.435 seconds\n",
      "INFO:root:Epoch[33] Evaluation metric 'epoch_loss'=-2.027547\n",
      "INFO:root:Epoch[34] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.54it/s, avg_epoch_loss=-1.71]\n",
      "INFO:root:Epoch[34] Elapsed time 104.856 seconds\n",
      "INFO:root:Epoch[34] Evaluation metric 'epoch_loss'=-1.713878\n",
      "INFO:root:Epoch[35] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.55it/s, avg_epoch_loss=-1.76]\n",
      "INFO:root:Epoch[35] Elapsed time 104.764 seconds\n",
      "INFO:root:Epoch[35] Evaluation metric 'epoch_loss'=-1.760879\n",
      "INFO:root:Epoch[36] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.58it/s, avg_epoch_loss=-2.05]\n",
      "INFO:root:Epoch[36] Elapsed time 104.391 seconds\n",
      "INFO:root:Epoch[36] Evaluation metric 'epoch_loss'=-2.049401\n",
      "INFO:root:Epoch[37] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.39it/s, avg_epoch_loss=-1.76]\n",
      "INFO:root:Epoch[37] Elapsed time 106.520 seconds\n",
      "INFO:root:Epoch[37] Evaluation metric 'epoch_loss'=-1.756426\n",
      "INFO:root:Epoch[38] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.45it/s, avg_epoch_loss=-1.79]\n",
      "INFO:root:Epoch[38] Elapsed time 105.777 seconds\n",
      "INFO:root:Epoch[38] Evaluation metric 'epoch_loss'=-1.790497\n",
      "INFO:root:Epoch[39] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.38it/s, avg_epoch_loss=-2.09]\n",
      "INFO:root:Epoch[39] Elapsed time 106.568 seconds\n",
      "INFO:root:Epoch[39] Evaluation metric 'epoch_loss'=-2.089663\n",
      "INFO:root:Epoch[40] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.54it/s, avg_epoch_loss=-1.78]\n",
      "INFO:root:Epoch[40] Elapsed time 104.871 seconds\n",
      "INFO:root:Epoch[40] Evaluation metric 'epoch_loss'=-1.778147\n",
      "INFO:root:Epoch[41] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.60it/s, avg_epoch_loss=-1.81]\n",
      "INFO:root:Epoch[41] Elapsed time 104.214 seconds\n",
      "INFO:root:Epoch[41] Evaluation metric 'epoch_loss'=-1.811829\n",
      "INFO:root:Epoch[42] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.54it/s, avg_epoch_loss=-2.11]\n",
      "INFO:root:Epoch[42] Elapsed time 104.877 seconds\n",
      "INFO:root:Epoch[42] Evaluation metric 'epoch_loss'=-2.113627\n",
      "INFO:root:Epoch[43] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.49it/s, avg_epoch_loss=-1.81]\n",
      "INFO:root:Epoch[43] Elapsed time 105.328 seconds\n",
      "INFO:root:Epoch[43] Evaluation metric 'epoch_loss'=-1.813078\n",
      "INFO:root:Epoch[44] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.45it/s, avg_epoch_loss=-1.84]\n",
      "INFO:root:Epoch[44] Elapsed time 105.770 seconds\n",
      "INFO:root:Epoch[44] Evaluation metric 'epoch_loss'=-1.840736\n",
      "INFO:root:Epoch[45] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.49it/s, avg_epoch_loss=-2.14]\n",
      "INFO:root:Epoch[45] Elapsed time 105.335 seconds\n",
      "INFO:root:Epoch[45] Evaluation metric 'epoch_loss'=-2.138010\n",
      "INFO:root:Epoch[46] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.54it/s, avg_epoch_loss=-1.84]\n",
      "INFO:root:Epoch[46] Elapsed time 104.840 seconds\n",
      "INFO:root:Epoch[46] Evaluation metric 'epoch_loss'=-1.840254\n",
      "INFO:root:Epoch[47] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.55it/s, avg_epoch_loss=-1.86]\n",
      "INFO:root:Epoch[47] Elapsed time 104.719 seconds\n",
      "INFO:root:Epoch[47] Evaluation metric 'epoch_loss'=-1.862232\n",
      "INFO:root:Epoch[48] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.57it/s, avg_epoch_loss=-2.16]\n",
      "INFO:root:Epoch[48] Elapsed time 104.450 seconds\n",
      "INFO:root:Epoch[48] Evaluation metric 'epoch_loss'=-2.164521\n",
      "INFO:root:Epoch[49] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.39it/s, avg_epoch_loss=-1.87]\n",
      "INFO:root:Epoch[49] Elapsed time 106.497 seconds\n",
      "INFO:root:Epoch[49] Evaluation metric 'epoch_loss'=-1.873609\n",
      "INFO:root:Loading parameters from best epoch (48)\n",
      "INFO:root:Final loss: -2.164521375671029 (occurred at epoch 48)\n",
      "INFO:root:End model training\n",
      "Running evaluation: 100%|██████████| 48000/48000 [17:44<00:00, 45.09it/s]\n",
      "INFO:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_monthly.\n",
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MASE': 1.03742146,\n",
      " 'MSIS': 21.90872632,\n",
      " 'epochs': 50,\n",
      " 'sMAPE': 0.13700314,\n",
      " 'seed': 42,\n",
      " 'wQuantileLoss[0.5]': 0.12313782,\n",
      " 'wQuantileLoss[0.9]': 0.09084201}\n",
      "None\n",
      "Seed: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of parameters in DeepStateTrainingNetwork: 2429349\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.44it/s, avg_epoch_loss=-.184]\n",
      "INFO:root:Epoch[0] Elapsed time 105.913 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=-0.183793\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.55it/s, avg_epoch_loss=-.181] \n",
      "INFO:root:Epoch[1] Elapsed time 104.742 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=-0.181230\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      " 10%|▉         | 97/1000 [00:10<01:33,  9.67it/s, avg_epoch_loss=-.117]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(42, 45):\n",
    "        print(\"Seed:\", i)\n",
    "        res = deep_state(data=\"m4_monthly\", seed=i, epochs=50, batches=1000)\n",
    "        pprint(res)\n",
    "        results.append(res)\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepState - use_feat_static=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_state_no_feat(seed=42, data=\"m4_daily\", epochs=25, batches=50):\n",
    "    dataset = get_dataset(data)\n",
    "\n",
    "    mx.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        ctx=mx.cpu(0),\n",
    "#         ctx=mx.gpu(0),\n",
    "        epochs=epochs,\n",
    "        num_batches_per_epoch=batches,\n",
    "        learning_rate=1e-3,\n",
    "    )\n",
    "\n",
    "    cardinality = int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "    estimator = DeepStateEstimator(\n",
    "        trainer=trainer,\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "#         past_length=48,\n",
    "#         use_feat_static_cat=True,\n",
    "#         cardinality=[cardinality],\n",
    "    )\n",
    "\n",
    "    predictor = estimator.train(dataset.train)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "    metrics = [\"MASE\", \"sMAPE\", \"MSIS\", \"wQuantileLoss[0.5]\", \"wQuantileLoss[0.9]\"]\n",
    "    output = {key: round(value, 8) for key, value in agg_metrics.items() if key in metrics}\n",
    "    output[\"epochs\"] = epochs\n",
    "    output[\"seed\"] = seed\n",
    "\n",
    "    pprint(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_monthly.\n",
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of parameters in DeepStateTrainingNetwork: 21510\n",
      "100%|██████████| 1000/1000 [01:37<00:00, 10.26it/s, avg_epoch_loss=-.278]\n",
      "INFO:root:Epoch[0] Elapsed time 97.444 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=-0.278151\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.49it/s, avg_epoch_loss=-.0851] \n",
      "INFO:root:Epoch[1] Elapsed time 95.304 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=-0.085067\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 10.40it/s, avg_epoch_loss=-.249]\n",
      "INFO:root:Epoch[2] Elapsed time 96.202 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=-0.249471\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.53it/s, avg_epoch_loss=-.408]\n",
      "INFO:root:Epoch[3] Elapsed time 95.009 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=-0.408244\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.51it/s, avg_epoch_loss=-.0808]\n",
      "INFO:root:Epoch[4] Elapsed time 95.115 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=-0.080787\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.45it/s, avg_epoch_loss=-.23]\n",
      "INFO:root:Epoch[5] Elapsed time 95.716 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=-0.230436\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 10.40it/s, avg_epoch_loss=-.414]\n",
      "INFO:root:Epoch[6] Elapsed time 96.152 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=-0.413956\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.44it/s, avg_epoch_loss=-.0899]\n",
      "INFO:root:Epoch[7] Elapsed time 95.777 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=-0.089928\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.42it/s, avg_epoch_loss=-.25]\n",
      "INFO:root:Epoch[8] Elapsed time 95.949 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=-0.249732\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 10.39it/s, avg_epoch_loss=-.426]\n",
      "INFO:root:Epoch[9] Elapsed time 96.220 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=-0.425821\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:35<00:00, 10.46it/s, avg_epoch_loss=-.0899]\n",
      "INFO:root:Epoch[10] Elapsed time 95.641 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=-0.089895\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 10.34it/s, avg_epoch_loss=-.241]\n",
      "INFO:root:Epoch[11] Elapsed time 96.725 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=-0.240553\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      " 63%|██████▎   | 630/1000 [01:01<00:36, 10.24it/s, avg_epoch_loss=-.207]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-208034f9b761>\u001b[0m in \u001b[0;36mdeep_state_no_feat\u001b[0;34m(seed, data, epochs, batches)\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     forecast_it, ts_it = make_evaluation_predictions(\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hybrid_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input_names, train_iter)\u001b[0m\n\u001b[1;32m    258\u001b[0m                             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                             it.set_postfix(\n\u001b[1;32m    262\u001b[0m                                 ordered_dict={\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, _, preds)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inst\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(42, 45):\n",
    "        print(\"Seed:\", i)\n",
    "        res = deep_state_no_feat(data=\"m4_monthly\", seed=i, epochs=50, batches=1000)\n",
    "        pprint(res)\n",
    "        results.append(res)\n",
    "    \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
