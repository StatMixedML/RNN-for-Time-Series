{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepState - Experiments\n",
    "\n",
    "- Using DeepState with gluonts to run some experiments\n",
    "- Follow this installation guide: http://gluon-ts-staging.s3-accelerate.dualstack.amazonaws.com/PR-271/4/install.html\n",
    "\n",
    "Important note! Some of these models are not yet released in version \"0.3.3\" which is currently the most recent version on pypi from where you install packages via `pip install`. Hence, you should follow **Install from Source Code** (which I did) **Install from Github**\n",
    "\n",
    "### Deep State Space Models (Rangapuram et al., 2018)\n",
    "\n",
    "**DeepState** combines state space models (SSM) with a recurrent neural network (RNN). The SSM is applied *locally* to the individual time series that is parametrized using a *global* representation in form of a RNN. The RNN is trained on the entire dataset. \n",
    "\n",
    "- [`DeepStateEstimator`](http://gluon-ts.mxnet.io/master/api/gluonts/gluonts.model.deepstate.html#gluonts.model.deepstate.DeepStateEstimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/awslabs/gluon-ts.git\n",
      "  Cloning https://github.com/awslabs/gluon-ts.git to /tmp/pip-req-build-ddvttyv_\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3==1.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev66+gac782de) (1.9.247)\n",
      "Collecting holidays==0.9.* (from gluonts==0.3.4.dev66+gac782de)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/17/a452275a0b3e811a381137ff6a61649086af4c5bf2a25755f518cc64b39e/holidays-0.9.11.tar.gz (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 2.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev66+gac782de) (3.0.3)\n",
      "Collecting mxnet<1.5.*,>=1.3.1 (from gluonts==0.3.4.dev66+gac782de)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f4/bc147a1ba7175f9890523ff8f1a928a43ac8a79d5897a067158cac4d092f/mxnet-1.4.1-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 1.8MB/s eta 0:00:011  27% |████████▉                       | 7.8MB 58.0MB/s eta 0:00:01    95% |██████████████████████████████▍ | 27.0MB 84.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.14.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev66+gac782de) (1.14.5)\n",
      "Collecting pandas>=0.25.0 (from gluonts==0.3.4.dev66+gac782de)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/12/08b092f6fc9e4c2552e37add0861d0e0e0d743f78f1318973caad970b3fc/pandas-0.25.2-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 8.4MB/s  eta 0:00:01   46% |██████████████▉                 | 4.8MB 86.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic==0.28.* (from gluonts==0.3.4.dev66+gac782de)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/bc/fe7d98f0b4b1e72d0c444f343a798461c1f9d8656fb1c335416dbb8b7976/pydantic-0.28-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.8MB 14.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting tqdm>=4.23.0 (from gluonts==0.3.4.dev66+gac782de)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 43.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ujson>=1.35 (from gluonts==0.3.4.dev66+gac782de)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 50.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev66+gac782de) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev66+gac782de) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.247 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev66+gac782de) (1.12.247)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev66+gac782de) (2.7.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev66+gac782de) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev66+gac782de) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev66+gac782de) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev66+gac782de) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev66+gac782de) (2.20.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev66+gac782de) (0.8.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.25.0->gluonts==0.3.4.dev66+gac782de) (2018.4)\n",
      "Collecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic==0.28.*->gluonts==0.3.4.dev66+gac782de)\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.247->boto3==1.*->gluonts==0.3.4.dev66+gac782de) (1.23)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.247->boto3==1.*->gluonts==0.3.4.dev66+gac782de) (0.14)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.*->gluonts==0.3.4.dev66+gac782de) (39.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev66+gac782de) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev66+gac782de) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev66+gac782de) (2.6)\n",
      "Building wheels for collected packages: gluonts, holidays, ujson\n",
      "  Running setup.py bdist_wheel for gluonts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-5sqzk37p/wheels/09/ba/b9/c830628df4d977a9dfe661f6001cdb861fc3f2524bac0ee433\n",
      "  Running setup.py bdist_wheel for holidays ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/40/a9/2b/94ac5464363d37564a87dc93a9d21a5850aac14a4608197003\n",
      "  Running setup.py bdist_wheel for ujson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "Successfully built gluonts holidays ujson\n",
      "Installing collected packages: holidays, mxnet, pandas, dataclasses, pydantic, tqdm, ujson, gluonts\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed dataclasses-0.6 gluonts-0.3.4.dev66+gac782de holidays-0.9.11 mxnet-1.4.1 pandas-0.25.2 pydantic-0.28 tqdm-4.36.1 ujson-1.35\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "0.3.4.dev66+gac782de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using CPU\n"
     ]
    }
   ],
   "source": [
    "# if version does not include DeepState, uncomment the following:\n",
    "!pip install git+https://github.com/awslabs/gluon-ts.git\n",
    "# !pip install mxnet-cu101\n",
    "\n",
    "import gluonts\n",
    "print(gluonts.__version__)\n",
    "\n",
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# vis imports \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# json\n",
    "import json\n",
    "\n",
    "# gluon data \n",
    "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "# gluon imports\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "# model imports \n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "# from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "# from gluonts.model.deepar import DeepAREstimator\n",
    "\n",
    "import mxnet as mx\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_state(seed=42, data=\"m4_daily\", epochs=25, batches=50):\n",
    "    dataset = get_dataset(data)\n",
    "\n",
    "    mx.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        ctx=mx.cpu(0),\n",
    "        epochs=epochs,\n",
    "        num_batches_per_epoch=batches,\n",
    "        learning_rate=1e-3,\n",
    "    )\n",
    "\n",
    "    cardinality = int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "    estimator = DeepStateEstimator(\n",
    "        trainer=trainer,\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "#         past_length=48,\n",
    "        use_feat_static_cat=True,\n",
    "        cardinality=[cardinality],\n",
    "    )\n",
    "\n",
    "    predictor = estimator.train(dataset.train)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "    metrics = [\"MASE\", \"sMAPE\", \"MSIS\", \"wQuantileLoss[0.5]\", \"wQuantileLoss[0.9]\"]\n",
    "    output = {key: round(value, 8) for key, value in agg_metrics.items() if key in metrics}\n",
    "\n",
    "    pprint(output)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     deep_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloading and processing m4_daily\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily/train/data.json\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily/test/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepStateTrainingNetwork: 240609\n",
      "100%|██████████| 50/50 [06:08<00:00,  7.38s/it, avg_epoch_loss=-1.4]    \n",
      "INFO:root:Epoch[0] Elapsed time 368.850 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=-1.396312\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.35s/it, avg_epoch_loss=0.0665]\n",
      "INFO:root:Epoch[1] Elapsed time 117.448 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=0.066499\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:56<00:00,  2.32s/it, avg_epoch_loss=-1.24]\n",
      "INFO:root:Epoch[2] Elapsed time 116.127 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=-1.238061\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.34s/it, avg_epoch_loss=-1.52]\n",
      "INFO:root:Epoch[3] Elapsed time 117.205 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=-1.518090\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-1.67]\n",
      "INFO:root:Epoch[4] Elapsed time 118.725 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=-1.674009\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:55<00:00,  2.31s/it, avg_epoch_loss=-1.73]\n",
      "INFO:root:Epoch[5] Elapsed time 115.566 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=-1.731139\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.35s/it, avg_epoch_loss=-1.57]\n",
      "INFO:root:Epoch[6] Elapsed time 117.487 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=-1.566241\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:56<00:00,  2.34s/it, avg_epoch_loss=-1.85]\n",
      "INFO:root:Epoch[7] Elapsed time 116.799 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=-1.851393\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:56<00:00,  2.33s/it, avg_epoch_loss=-2.25]\n",
      "INFO:root:Epoch[8] Elapsed time 116.336 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=-2.248113\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      " 50%|█████     | 25/50 [00:58<00:58,  2.36s/it, avg_epoch_loss=-2.03]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=42, data=\"m4_daily\", epochs=25, batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloading and processing m4_daily\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily/train/data.json\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily/test/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepStateTrainingNetwork: 240609\n",
      "100%|██████████| 50/50 [05:57<00:00,  7.14s/it, avg_epoch_loss=-1.4]    \n",
      "INFO:root:Epoch[0] Elapsed time 357.026 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=-1.396312\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it, avg_epoch_loss=0.0665]\n",
      "INFO:root:Epoch[1] Elapsed time 118.125 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=0.066499\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.34s/it, avg_epoch_loss=-1.24]\n",
      "INFO:root:Epoch[2] Elapsed time 117.085 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=-1.238061\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-1.52]\n",
      "INFO:root:Epoch[3] Elapsed time 117.825 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=-1.518090\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-1.67]\n",
      "INFO:root:Epoch[4] Elapsed time 118.433 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=-1.674009\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.35s/it, avg_epoch_loss=-1.73]\n",
      "INFO:root:Epoch[5] Elapsed time 117.682 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=-1.731139\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.35s/it, avg_epoch_loss=-1.57]\n",
      "INFO:root:Epoch[6] Elapsed time 117.643 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=-1.566241\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it, avg_epoch_loss=-1.85]\n",
      "INFO:root:Epoch[7] Elapsed time 118.197 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=-1.851393\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.25]\n",
      "INFO:root:Epoch[8] Elapsed time 117.947 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=-2.248113\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.14]\n",
      "INFO:root:Epoch[9] Elapsed time 117.833 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=-2.142390\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it, avg_epoch_loss=-2.36]\n",
      "INFO:root:Epoch[10] Elapsed time 118.219 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=-2.362707\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.38s/it, avg_epoch_loss=-2.34]\n",
      "INFO:root:Epoch[11] Elapsed time 118.793 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=-2.339449\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-2.34]\n",
      "INFO:root:Epoch[12] Elapsed time 118.440 seconds\n",
      "INFO:root:Epoch[12] Evaluation metric 'epoch_loss'=-2.343836\n",
      "INFO:root:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.38]\n",
      "INFO:root:Epoch[13] Elapsed time 117.845 seconds\n",
      "INFO:root:Epoch[13] Evaluation metric 'epoch_loss'=-2.381656\n",
      "INFO:root:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.38s/it, avg_epoch_loss=-2.31]\n",
      "INFO:root:Epoch[14] Elapsed time 118.933 seconds\n",
      "INFO:root:Epoch[14] Evaluation metric 'epoch_loss'=-2.313464\n",
      "INFO:root:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.37]\n",
      "INFO:root:Epoch[15] Elapsed time 117.825 seconds\n",
      "INFO:root:Epoch[15] Evaluation metric 'epoch_loss'=-2.374188\n",
      "INFO:root:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-2.46]\n",
      "INFO:root:Epoch[16] Elapsed time 118.331 seconds\n",
      "INFO:root:Epoch[16] Evaluation metric 'epoch_loss'=-2.464368\n",
      "INFO:root:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it, avg_epoch_loss=-2.29]\n",
      "INFO:root:Epoch[17] Elapsed time 118.043 seconds\n",
      "INFO:root:Epoch[17] Evaluation metric 'epoch_loss'=-2.290284\n",
      "INFO:root:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:56<00:00,  2.33s/it, avg_epoch_loss=-2.46]\n",
      "INFO:root:Epoch[18] Elapsed time 116.438 seconds\n",
      "INFO:root:Epoch[18] Evaluation metric 'epoch_loss'=-2.460619\n",
      "INFO:root:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it, avg_epoch_loss=-2.37]\n",
      "INFO:root:Epoch[19] Elapsed time 118.034 seconds\n",
      "INFO:root:Epoch[19] Evaluation metric 'epoch_loss'=-2.365769\n",
      "INFO:root:Epoch[20] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.43]\n",
      "INFO:root:Epoch[20] Elapsed time 117.930 seconds\n",
      "INFO:root:Epoch[20] Evaluation metric 'epoch_loss'=-2.427326\n",
      "INFO:root:Epoch[21] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [02:03<00:00,  2.46s/it, avg_epoch_loss=-2.42]\n",
      "INFO:root:Epoch[21] Elapsed time 123.212 seconds\n",
      "INFO:root:Epoch[21] Evaluation metric 'epoch_loss'=-2.415319\n",
      "INFO:root:Epoch[22] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.38s/it, avg_epoch_loss=-2.36]\n",
      "INFO:root:Epoch[22] Elapsed time 118.842 seconds\n",
      "INFO:root:Epoch[22] Evaluation metric 'epoch_loss'=-2.358051\n",
      "INFO:root:Epoch[23] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-2.46]\n",
      "INFO:root:Epoch[23] Elapsed time 118.325 seconds\n",
      "INFO:root:Epoch[23] Evaluation metric 'epoch_loss'=-2.461363\n",
      "INFO:root:Epoch[24] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.35s/it, avg_epoch_loss=-2.46]\n",
      "INFO:root:Epoch[24] Elapsed time 117.493 seconds\n",
      "INFO:root:Epoch[24] Evaluation metric 'epoch_loss'=-2.455898\n",
      "INFO:root:Epoch[25] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-2.35]\n",
      "INFO:root:Epoch[25] Elapsed time 118.348 seconds\n",
      "INFO:root:Epoch[25] Evaluation metric 'epoch_loss'=-2.350821\n",
      "INFO:root:Epoch[26] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.35s/it, avg_epoch_loss=-2.48]\n",
      "INFO:root:Epoch[26] Elapsed time 117.267 seconds\n",
      "INFO:root:Epoch[26] Evaluation metric 'epoch_loss'=-2.479529\n",
      "INFO:root:Epoch[27] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:59<00:00,  2.39s/it, avg_epoch_loss=-2.4] \n",
      "INFO:root:Epoch[27] Elapsed time 119.328 seconds\n",
      "INFO:root:Epoch[27] Evaluation metric 'epoch_loss'=-2.400658\n",
      "INFO:root:Epoch[28] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:59<00:00,  2.39s/it, avg_epoch_loss=-2.48]\n",
      "INFO:root:Epoch[28] Elapsed time 119.255 seconds\n",
      "INFO:root:Epoch[28] Evaluation metric 'epoch_loss'=-2.476721\n",
      "INFO:root:Epoch[29] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-2.48]\n",
      "INFO:root:Epoch[29] Elapsed time 118.426 seconds\n",
      "INFO:root:Epoch[29] Evaluation metric 'epoch_loss'=-2.484212\n",
      "INFO:root:Epoch[30] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.37]\n",
      "INFO:root:Epoch[30] Elapsed time 117.848 seconds\n",
      "INFO:root:Epoch[30] Evaluation metric 'epoch_loss'=-2.371444\n",
      "INFO:root:Epoch[31] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.36s/it, avg_epoch_loss=-2.57]\n",
      "INFO:root:Epoch[31] Elapsed time 118.243 seconds\n",
      "INFO:root:Epoch[31] Evaluation metric 'epoch_loss'=-2.569650\n",
      "INFO:root:Epoch[32] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:58<00:00,  2.37s/it, avg_epoch_loss=-2.47]\n",
      "INFO:root:Epoch[32] Elapsed time 118.501 seconds\n",
      "INFO:root:Epoch[32] Evaluation metric 'epoch_loss'=-2.468753\n",
      "INFO:root:Epoch[33] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:59<00:00,  2.38s/it, avg_epoch_loss=-2.4] \n",
      "INFO:root:Epoch[33] Elapsed time 119.205 seconds\n",
      "INFO:root:Epoch[33] Evaluation metric 'epoch_loss'=-2.398142\n",
      "INFO:root:Epoch[34] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, avg_epoch_loss=-2.56]\n",
      "INFO:root:Epoch[34] Elapsed time 117.985 seconds\n",
      "INFO:root:Epoch[34] Evaluation metric 'epoch_loss'=-2.556281\n",
      "INFO:root:Loading parameters from best epoch (31)\n",
      "INFO:root:Final loss: -2.569649701118469 (occurred at epoch 31)\n",
      "INFO:root:End model training\n",
      "Running evaluation: 100%|██████████| 4227/4227 [11:12<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MASE': 3.95988776,\n",
      " 'MSIS': 71.02142783,\n",
      " 'sMAPE': 0.03622678,\n",
      " 'wQuantileLoss[0.5]': 0.033905,\n",
      " 'wQuantileLoss[0.9]': 0.02346546}\n",
      "CPU times: user 3h 7min 52s, sys: 3min 13s, total: 3h 11min 5s\n",
      "Wall time: 1h 25min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=42, data=\"m4_daily\", epochs=35, batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily.\n",
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepStateTrainingNetwork: 240609\n",
      "100%|██████████| 50/50 [06:09<00:00,  7.38s/it, avg_epoch_loss=-1.4]    \n",
      "INFO:root:Epoch[0] Elapsed time 369.019 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=-1.396312\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      " 10%|█         | 5/50 [00:14<02:12,  2.95s/it, avg_epoch_loss=-1.23]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7f7eb575f62f>\u001b[0m in \u001b[0;36mdeep_state\u001b[0;34m(seed, data, epochs, batches)\u001b[0m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     forecast_it, ts_it = make_evaluation_predictions(\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hybrid_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input_names, train_iter)\u001b[0m\n\u001b[1;32m    255\u001b[0m                                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2198\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=42, data=\"m4_daily\", epochs=45, batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=43, data=\"m4_daily\", epochs=35, batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=43, data=\"m4_daily\", epochs=45, batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=44, data=\"m4_daily\", epochs=35, batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    deep_state(seed=44, data=\"m4_daily\", epochs=45, batches=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
