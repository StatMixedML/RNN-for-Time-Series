{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFactor - Experiments\n",
    "\n",
    "### Deep Factor (Wang et al.,  2019)\n",
    "\n",
    "Hybrid method that uses *local* methods that are specific to each time series in the dataset as well as a *global* representation trained on the entire data. The latter is a RNN to learn universal pattern. The current version uses another RNN as local model -> **DeepFactor-RNN (DF-RNN)**\n",
    "\n",
    "- [`DeepFactorEstimator`](http://gluon-ts.mxnet.io/master/api/gluonts/gluonts.model.deep_factor.html?highlight=deepfactorestimator#gluonts.model.deep_factor.DeepFactorEstimator)\n",
    "- [Wang et al. (2019)](https://arxiv.org/abs/1905.12417)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/awslabs/gluon-ts.git\n",
      "  Cloning https://github.com/awslabs/gluon-ts.git to /tmp/pip-req-build-b3qm33by\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3==1.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev68+ga894aee) (1.9.253)\n",
      "Collecting holidays==0.9.* (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/17/a452275a0b3e811a381137ff6a61649086af4c5bf2a25755f518cc64b39e/holidays-0.9.11.tar.gz (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 2.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev68+ga894aee) (3.0.3)\n",
      "Collecting mxnet<1.5.*,>=1.3.1 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f4/bc147a1ba7175f9890523ff8f1a928a43ac8a79d5897a067158cac4d092f/mxnet-1.4.1-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 1.9MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.14.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev68+ga894aee) (1.14.5)\n",
      "Collecting pandas>=0.25.0 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/12/08b092f6fc9e4c2552e37add0861d0e0e0d743f78f1318973caad970b3fc/pandas-0.25.2-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 8.1MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic==0.28.* (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/bc/fe7d98f0b4b1e72d0c444f343a798461c1f9d8656fb1c335416dbb8b7976/pydantic-0.28-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.8MB 15.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.23.0 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 41.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ujson>=1.35 (from gluonts==0.3.4.dev68+ga894aee)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 53.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (1.12.253)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev68+ga894aee) (2.7.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev68+ga894aee) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (2.20.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (0.8.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.25.0->gluonts==0.3.4.dev68+ga894aee) (2018.4)\n",
      "Collecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic==0.28.*->gluonts==0.3.4.dev68+ga894aee)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.253->boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (1.23)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.253->boto3==1.*->gluonts==0.3.4.dev68+ga894aee) (0.14)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.*->gluonts==0.3.4.dev68+ga894aee) (39.1.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.3.1->gluonts==0.3.4.dev68+ga894aee) (2019.6.16)\n",
      "Building wheels for collected packages: gluonts, holidays, ujson\n",
      "  Running setup.py bdist_wheel for gluonts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-9yfs7ttd/wheels/09/ba/b9/c830628df4d977a9dfe661f6001cdb861fc3f2524bac0ee433\n",
      "  Running setup.py bdist_wheel for holidays ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/40/a9/2b/94ac5464363d37564a87dc93a9d21a5850aac14a4608197003\n",
      "  Running setup.py bdist_wheel for ujson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "Successfully built gluonts holidays ujson\n",
      "Installing collected packages: holidays, mxnet, pandas, dataclasses, pydantic, tqdm, ujson, gluonts\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed dataclasses-0.7 gluonts-0.3.4.dev68+ga894aee holidays-0.9.11 mxnet-1.4.1 pandas-0.25.2 pydantic-0.28 tqdm-4.36.1 ujson-1.35\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "0.3.4.dev68+ga894aee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using CPU\n"
     ]
    }
   ],
   "source": [
    "# if version does not include DeepState, uncomment the following:\n",
    "!pip install git+https://github.com/awslabs/gluon-ts.git\n",
    "\n",
    "import gluonts\n",
    "print(gluonts.__version__)\n",
    "\n",
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# vis imports \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# json\n",
    "import json\n",
    "\n",
    "# gluon data \n",
    "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "# gluon imports\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "# gluon distribution\n",
    "from gluonts.distribution.piecewise_linear import PiecewiseLinearOutput\n",
    "from gluonts.distribution.gaussian import GaussianOutput\n",
    "\n",
    "# model imports \n",
    "# from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "# from gluonts.model.deepar import DeepAREstimator\n",
    "\n",
    "import mxnet as mx\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed=42, data=\"m4_daily\", epochs=100, batches=50):\n",
    "    \n",
    "    mx.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    dataset = get_dataset(data)\n",
    "    trainer = Trainer(\n",
    "        ctx=mx.cpu(0),\n",
    "        epochs=epochs,\n",
    "        num_batches_per_epoch=batches,\n",
    "        learning_rate=1e-3,\n",
    "    )\n",
    "\n",
    "    cardinality = int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "    estimator = DeepFactorEstimator(\n",
    "        trainer=trainer,\n",
    "        cardinality=[cardinality],\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "#         num_layers_global=2,\n",
    "#         num_layers_local=2\n",
    "    )\n",
    "\n",
    "    predictor = estimator.train(dataset.train)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "    metrics = [\"MASE\", \"sMAPE\", \"MSIS\", \"wQuantileLoss[0.5]\", \"wQuantileLoss[0.9]\"]\n",
    "    output = {key: round(value, 8) for key, value in agg_metrics.items() if key in metrics}\n",
    "\n",
    "    pprint(output)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     simple_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloading and processing m4_daily\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily/train/data.json\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_daily/test/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepFactorTrainingNetwork: 54286\n",
      "100%|██████████| 250/250 [00:05<00:00, 44.84it/s, avg_epoch_loss=3.07e+7]\n",
      "INFO:root:Epoch[0] Elapsed time 5.578 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=30734681.082286\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 45.54it/s, avg_epoch_loss=2.91e+6]\n",
      "INFO:root:Epoch[1] Elapsed time 5.492 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=2912758.646714\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 44.73it/s, avg_epoch_loss=8.15e+5]\n",
      "INFO:root:Epoch[2] Elapsed time 5.592 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=815320.469607\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 45.23it/s, avg_epoch_loss=3.71e+5]\n",
      "INFO:root:Epoch[3] Elapsed time 5.531 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=371136.556643\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 43.63it/s, avg_epoch_loss=2.28e+5]\n",
      "INFO:root:Epoch[4] Elapsed time 5.732 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=227653.714000\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 42.13it/s, avg_epoch_loss=1.52e+5]\n",
      "INFO:root:Epoch[5] Elapsed time 5.937 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=152120.015259\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 44.96it/s, avg_epoch_loss=1.05e+5]\n",
      "INFO:root:Epoch[6] Elapsed time 5.563 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=105228.172621\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 43.38it/s, avg_epoch_loss=8.32e+4]\n",
      "INFO:root:Epoch[7] Elapsed time 5.766 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=83230.004219\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 43.17it/s, avg_epoch_loss=7.54e+4]\n",
      "INFO:root:Epoch[8] Elapsed time 5.793 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=75416.778114\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 43.52it/s, avg_epoch_loss=4.67e+4]\n",
      "INFO:root:Epoch[9] Elapsed time 5.747 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=46659.743280\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 42.40it/s, avg_epoch_loss=3.8e+4]\n",
      "INFO:root:Epoch[10] Elapsed time 5.898 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=38000.512318\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 44.37it/s, avg_epoch_loss=3.14e+4]\n",
      "INFO:root:Epoch[11] Elapsed time 5.636 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=31404.817100\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:06<00:00, 38.59it/s, avg_epoch_loss=2.31e+4]\n",
      "INFO:root:Epoch[12] Elapsed time 6.480 seconds\n",
      "INFO:root:Epoch[12] Evaluation metric 'epoch_loss'=23071.031373\n",
      "INFO:root:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:05<00:00, 44.28it/s, avg_epoch_loss=2.04e+4]\n",
      "INFO:root:Epoch[13] Elapsed time 5.649 seconds\n",
      "INFO:root:Epoch[13] Evaluation metric 'epoch_loss'=20438.609819\n",
      "INFO:root:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:06<00:00, 41.41it/s, avg_epoch_loss=1.76e+4]\n",
      "INFO:root:Epoch[14] Elapsed time 6.041 seconds\n",
      "INFO:root:Epoch[14] Evaluation metric 'epoch_loss'=17574.628006\n",
      "INFO:root:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 33.86it/s, avg_epoch_loss=1.39e+4]\n",
      "INFO:root:Epoch[15] Elapsed time 7.389 seconds\n",
      "INFO:root:Epoch[15] Evaluation metric 'epoch_loss'=13885.803519\n",
      "INFO:root:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.32it/s, avg_epoch_loss=1.09e+4]\n",
      "INFO:root:Epoch[16] Elapsed time 7.987 seconds\n",
      "INFO:root:Epoch[16] Evaluation metric 'epoch_loss'=10870.594192\n",
      "INFO:root:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 32.39it/s, avg_epoch_loss=8.7e+3]\n",
      "INFO:root:Epoch[17] Elapsed time 7.724 seconds\n",
      "INFO:root:Epoch[17] Evaluation metric 'epoch_loss'=8696.269376\n",
      "INFO:root:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.46it/s, avg_epoch_loss=9.66e+3]\n",
      "INFO:root:Epoch[18] Elapsed time 8.493 seconds\n",
      "INFO:root:Epoch[18] Evaluation metric 'epoch_loss'=9663.183103\n",
      "INFO:root:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 26.58it/s, avg_epoch_loss=7.58e+3]\n",
      "INFO:root:Epoch[19] Elapsed time 9.412 seconds\n",
      "INFO:root:Epoch[19] Evaluation metric 'epoch_loss'=7579.573560\n",
      "INFO:root:Epoch[20] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 27.17it/s, avg_epoch_loss=6.1e+3]\n",
      "INFO:root:Epoch[20] Elapsed time 9.208 seconds\n",
      "INFO:root:Epoch[20] Evaluation metric 'epoch_loss'=6101.211744\n",
      "INFO:root:Epoch[21] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 32.23it/s, avg_epoch_loss=5.74e+3]\n",
      "INFO:root:Epoch[21] Elapsed time 7.760 seconds\n",
      "INFO:root:Epoch[21] Evaluation metric 'epoch_loss'=5736.698672\n",
      "INFO:root:Epoch[22] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 30.13it/s, avg_epoch_loss=4.93e+3]\n",
      "INFO:root:Epoch[22] Elapsed time 8.302 seconds\n",
      "INFO:root:Epoch[22] Evaluation metric 'epoch_loss'=4931.108258\n",
      "INFO:root:Epoch[23] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 27.37it/s, avg_epoch_loss=4.65e+3]\n",
      "INFO:root:Epoch[23] Elapsed time 9.140 seconds\n",
      "INFO:root:Epoch[23] Evaluation metric 'epoch_loss'=4652.896931\n",
      "INFO:root:Epoch[24] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 28.51it/s, avg_epoch_loss=4.3e+3]\n",
      "INFO:root:Epoch[24] Elapsed time 8.774 seconds\n",
      "INFO:root:Epoch[24] Evaluation metric 'epoch_loss'=4295.022166\n",
      "INFO:root:Epoch[25] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 30.21it/s, avg_epoch_loss=3.87e+3]\n",
      "INFO:root:Epoch[25] Elapsed time 8.283 seconds\n",
      "INFO:root:Epoch[25] Evaluation metric 'epoch_loss'=3873.614789\n",
      "INFO:root:Epoch[26] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 26.70it/s, avg_epoch_loss=3.48e+3]\n",
      "INFO:root:Epoch[26] Elapsed time 9.369 seconds\n",
      "INFO:root:Epoch[26] Evaluation metric 'epoch_loss'=3479.526043\n",
      "INFO:root:Epoch[27] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 27.24it/s, avg_epoch_loss=3.27e+3]\n",
      "INFO:root:Epoch[27] Elapsed time 9.185 seconds\n",
      "INFO:root:Epoch[27] Evaluation metric 'epoch_loss'=3272.752034\n",
      "INFO:root:Epoch[28] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 28.79it/s, avg_epoch_loss=3.06e+3]\n",
      "INFO:root:Epoch[28] Elapsed time 8.689 seconds\n",
      "INFO:root:Epoch[28] Evaluation metric 'epoch_loss'=3060.580279\n",
      "INFO:root:Epoch[29] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 35.46it/s, avg_epoch_loss=2.53e+3]\n",
      "INFO:root:Epoch[29] Elapsed time 7.057 seconds\n",
      "INFO:root:Epoch[29] Evaluation metric 'epoch_loss'=2534.853012\n",
      "INFO:root:Epoch[30] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.33it/s, avg_epoch_loss=2.47e+3]\n",
      "INFO:root:Epoch[30] Elapsed time 7.984 seconds\n",
      "INFO:root:Epoch[30] Evaluation metric 'epoch_loss'=2472.986919\n",
      "INFO:root:Epoch[31] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:06<00:00, 37.61it/s, avg_epoch_loss=2.25e+3]\n",
      "INFO:root:Epoch[31] Elapsed time 6.653 seconds\n",
      "INFO:root:Epoch[31] Evaluation metric 'epoch_loss'=2251.153223\n",
      "INFO:root:Epoch[32] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.42it/s, avg_epoch_loss=2.29e+3]\n",
      "INFO:root:Epoch[32] Elapsed time 7.961 seconds\n",
      "INFO:root:Epoch[32] Evaluation metric 'epoch_loss'=2287.572466\n",
      "INFO:root:Epoch[33] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 27.79it/s, avg_epoch_loss=2.05e+3]\n",
      "INFO:root:Epoch[33] Elapsed time 9.002 seconds\n",
      "INFO:root:Epoch[33] Evaluation metric 'epoch_loss'=2053.018063\n",
      "INFO:root:Epoch[34] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 26.71it/s, avg_epoch_loss=1.9e+3]\n",
      "INFO:root:Epoch[34] Elapsed time 9.366 seconds\n",
      "INFO:root:Epoch[34] Evaluation metric 'epoch_loss'=1896.550446\n",
      "INFO:root:Epoch[35] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.49it/s, avg_epoch_loss=1.58e+3]\n",
      "INFO:root:Epoch[35] Elapsed time 7.947 seconds\n",
      "INFO:root:Epoch[35] Evaluation metric 'epoch_loss'=1576.473305\n",
      "INFO:root:Epoch[36] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.24it/s, avg_epoch_loss=1.36e+3]\n",
      "INFO:root:Epoch[36] Elapsed time 8.554 seconds\n",
      "INFO:root:Epoch[36] Evaluation metric 'epoch_loss'=1355.748698\n",
      "INFO:root:Epoch[37] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 25.45it/s, avg_epoch_loss=1.04e+3]\n",
      "INFO:root:Epoch[37] Elapsed time 9.826 seconds\n",
      "INFO:root:Epoch[37] Evaluation metric 'epoch_loss'=1035.342615\n",
      "INFO:root:Epoch[38] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 25.81it/s, avg_epoch_loss=875]\n",
      "INFO:root:Epoch[38] Elapsed time 9.692 seconds\n",
      "INFO:root:Epoch[38] Evaluation metric 'epoch_loss'=874.992519\n",
      "INFO:root:Epoch[39] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 31.04it/s, avg_epoch_loss=755]\n",
      "INFO:root:Epoch[39] Elapsed time 8.063 seconds\n",
      "INFO:root:Epoch[39] Evaluation metric 'epoch_loss'=755.119395\n",
      "INFO:root:Epoch[40] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 27.42it/s, avg_epoch_loss=681]\n",
      "INFO:root:Epoch[40] Elapsed time 9.126 seconds\n",
      "INFO:root:Epoch[40] Evaluation metric 'epoch_loss'=680.502922\n",
      "INFO:root:Epoch[41] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.50it/s, avg_epoch_loss=622]\n",
      "INFO:root:Epoch[41] Elapsed time 7.944 seconds\n",
      "INFO:root:Epoch[41] Evaluation metric 'epoch_loss'=622.048471\n",
      "INFO:root:Epoch[42] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 31.22it/s, avg_epoch_loss=551]\n",
      "INFO:root:Epoch[42] Elapsed time 8.013 seconds\n",
      "INFO:root:Epoch[42] Evaluation metric 'epoch_loss'=550.999992\n",
      "INFO:root:Epoch[43] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 30.60it/s, avg_epoch_loss=544]\n",
      "INFO:root:Epoch[43] Elapsed time 8.177 seconds\n",
      "INFO:root:Epoch[43] Evaluation metric 'epoch_loss'=543.751933\n",
      "INFO:root:Epoch[44] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.15it/s, avg_epoch_loss=575]\n",
      "INFO:root:Epoch[44] Elapsed time 8.583 seconds\n",
      "INFO:root:Epoch[44] Evaluation metric 'epoch_loss'=575.070134\n",
      "INFO:root:Epoch[45] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 26.36it/s, avg_epoch_loss=531]\n",
      "INFO:root:Epoch[45] Elapsed time 9.489 seconds\n",
      "INFO:root:Epoch[45] Evaluation metric 'epoch_loss'=530.938734\n",
      "INFO:root:Epoch[46] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 26.33it/s, avg_epoch_loss=396]\n",
      "INFO:root:Epoch[46] Elapsed time 9.499 seconds\n",
      "INFO:root:Epoch[46] Evaluation metric 'epoch_loss'=395.649653\n",
      "INFO:root:Epoch[47] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 30.88it/s, avg_epoch_loss=452]\n",
      "INFO:root:Epoch[47] Elapsed time 8.101 seconds\n",
      "INFO:root:Epoch[47] Evaluation metric 'epoch_loss'=451.895290\n",
      "INFO:root:Epoch[48] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.90it/s, avg_epoch_loss=439]\n",
      "INFO:root:Epoch[48] Elapsed time 7.840 seconds\n",
      "INFO:root:Epoch[48] Evaluation metric 'epoch_loss'=439.078274\n",
      "INFO:root:Epoch[49] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 35.14it/s, avg_epoch_loss=394]\n",
      "INFO:root:Epoch[49] Elapsed time 7.117 seconds\n",
      "INFO:root:Epoch[49] Evaluation metric 'epoch_loss'=394.227397\n",
      "INFO:root:Epoch[50] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:07<00:00, 32.23it/s, avg_epoch_loss=406]\n",
      "INFO:root:Epoch[50] Elapsed time 7.762 seconds\n",
      "INFO:root:Epoch[50] Evaluation metric 'epoch_loss'=405.580145\n",
      "INFO:root:Epoch[51] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 28.21it/s, avg_epoch_loss=374]\n",
      "INFO:root:Epoch[51] Elapsed time 8.866 seconds\n",
      "INFO:root:Epoch[51] Evaluation metric 'epoch_loss'=374.100672\n",
      "INFO:root:Epoch[52] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.93it/s, avg_epoch_loss=351]\n",
      "INFO:root:Epoch[52] Elapsed time 8.360 seconds\n",
      "INFO:root:Epoch[52] Evaluation metric 'epoch_loss'=351.025049\n",
      "INFO:root:Epoch[53] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.03it/s, avg_epoch_loss=278]\n",
      "INFO:root:Epoch[53] Elapsed time 8.621 seconds\n",
      "INFO:root:Epoch[53] Evaluation metric 'epoch_loss'=277.667496\n",
      "INFO:root:Epoch[54] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 28.89it/s, avg_epoch_loss=248]\n",
      "INFO:root:Epoch[54] Elapsed time 8.659 seconds\n",
      "INFO:root:Epoch[54] Evaluation metric 'epoch_loss'=247.717425\n",
      "INFO:root:Epoch[55] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 27.72it/s, avg_epoch_loss=318]\n",
      "INFO:root:Epoch[55] Elapsed time 9.024 seconds\n",
      "INFO:root:Epoch[55] Evaluation metric 'epoch_loss'=317.785941\n",
      "INFO:root:Epoch[56] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:09<00:00, 27.74it/s, avg_epoch_loss=251]\n",
      "INFO:root:Epoch[56] Elapsed time 9.017 seconds\n",
      "INFO:root:Epoch[56] Evaluation metric 'epoch_loss'=250.637112\n",
      "INFO:root:Epoch[57] Learning rate is 0.001\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.62it/s, avg_epoch_loss=nan]\n",
      "INFO:root:Epoch[57] Elapsed time 8.446 seconds\n"
     ]
    },
    {
     "ename": "GluonTSDataError",
     "evalue": "Encountered invalid loss value! Try reducing the learning rate or try a different likelihood.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGluonTSDataError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-79d162b56e2c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(seed, data, epochs, batches)\u001b[0m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     forecast_it, ts_it = make_evaluation_predictions(\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hybrid_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input_names, train_iter)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;31m# check and log epoch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0mcheck_loss_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                     logging.info(\n\u001b[1;32m    286\u001b[0m                         \u001b[0;34m\"Epoch[%d] Evaluation metric '%s'=%f\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36mcheck_loss_finite\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         raise GluonTSDataError(\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;34m\"Encountered invalid loss value! Try reducing the learning rate \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;34m\"or try a different likelihood.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         )\n",
      "\u001b[0;31mGluonTSDataError\u001b[0m: Encountered invalid loss value! Try reducing the learning rate or try a different likelihood."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    main(seed=42, data=\"m4_daily\", epochs=100, batches=250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
