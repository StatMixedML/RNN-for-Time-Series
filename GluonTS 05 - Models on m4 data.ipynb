{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark m4\n",
    "\n",
    "How to fit several model and evaluate its predictions on three of subsets of M4 data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functools.partial\n",
    "\n",
    "Return a new `partial` object which when called will behave like *func* called with the positional arguments args and keyword arguments keywords. \n",
    "\n",
    "- [Source](https://docs.python.org/2/library/functools.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods  \n",
    "\n",
    "Brief overview of the used methods\n",
    "\n",
    "### `DeepAREstimator`\n",
    "\n",
    "- [`gluonts.model.deepar`](https://gluon-ts.mxnet.io/api/gluonts/gluonts.model.deepar.html)\n",
    "\n",
    "Construct a DeepAR estimator, implements an RNN-based model, close to the one described in\n",
    "\n",
    "- Salinas, David, Valentin Flunkert, and Jan Gasthaus. “DeepAR: Probabilistic forecasting with autoregressive recurrent networks.” arXiv preprint arXiv:1704.04110 (2017).\n",
    "\n",
    "\n",
    "### `MQCNNEstimator`\n",
    "\n",
    "- [`gluonts.model.seq2seq`](http://gluon-ts.mxnet.io/api/gluonts/gluonts.model.seq2seq.html)\n",
    "\n",
    "An `MQDNNEstimator` with Convolutional Neural Network (CNN) as an encoder. Implements the MQ-CNN Forecaster, proposed in \n",
    "\n",
    "- Wen, Ruofeng, et al. “A multi-horizon quantile recurrent forecaster.” arXiv preprint arXiv:1711.11053 (2017).\n",
    "\n",
    "\n",
    "### `SimpleFeedForwardEstimator`\n",
    "\n",
    "- [`gluonts.model.simple_feedforward`](http://gluon-ts.mxnet.io/api/gluonts/gluonts.model.simple_feedforward.html)\n",
    "\n",
    "A simple multilayer perceptron model predicting the next target time-steps given the previous ones. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/awslabs/gluon-ts.git\n",
      "  Cloning https://github.com/awslabs/gluon-ts.git to /tmp/pip-req-build-ge8yi7_m\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3==1.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (1.10.5)\n",
      "Collecting holidays==0.9.* (from gluonts==0.3.4.dev79+g481fc5f)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/17/a452275a0b3e811a381137ff6a61649086af4c5bf2a25755f518cc64b39e/holidays-0.9.11.tar.gz (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 5.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (3.0.3)\n",
      "Collecting mxnet<1.5.*,>=1.4.1 (from gluonts==0.3.4.dev79+g481fc5f)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f4/bc147a1ba7175f9890523ff8f1a928a43ac8a79d5897a067158cac4d092f/mxnet-1.4.1-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.14.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (1.14.5)\n",
      "Collecting pandas>=0.25.0 (from gluonts==0.3.4.dev79+g481fc5f)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic==0.28.* (from gluonts==0.3.4.dev79+g481fc5f)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/bc/fe7d98f0b4b1e72d0c444f343a798461c1f9d8656fb1c335416dbb8b7976/pydantic-0.28-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.8MB 10.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.23.0 (from gluonts==0.3.4.dev79+g481fc5f)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/f2/764a5d530cf143ded9bc95216edb6e258c6554511e78de7c250557e8f3ed/tqdm-4.37.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 31.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ujson>=1.35 (from gluonts==0.3.4.dev79+g481fc5f)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 15.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (1.13.5)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev79+g481fc5f) (2.7.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev79+g481fc5f) (1.11.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (2.20.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (0.8.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.25.0->gluonts==0.3.4.dev79+g481fc5f) (2018.4)\n",
      "Collecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic==0.28.*->gluonts==0.3.4.dev79+g481fc5f)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.5->boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (1.23)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.5->boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (0.14)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (39.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (2.6)\n",
      "Building wheels for collected packages: gluonts, holidays, ujson\n",
      "  Running setup.py bdist_wheel for gluonts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-8jwmure5/wheels/09/ba/b9/c830628df4d977a9dfe661f6001cdb861fc3f2524bac0ee433\n",
      "  Running setup.py bdist_wheel for holidays ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/40/a9/2b/94ac5464363d37564a87dc93a9d21a5850aac14a4608197003\n",
      "  Running setup.py bdist_wheel for ujson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "Successfully built gluonts holidays ujson\n",
      "Installing collected packages: holidays, mxnet, pandas, dataclasses, pydantic, tqdm, ujson, gluonts\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed dataclasses-0.7 gluonts-0.3.4.dev79+g481fc5f holidays-0.9.11 mxnet-1.4.1 pandas-0.25.3 pydantic-0.28 tqdm-4.37.0 ujson-1.35\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install gluonts (most recent version)\n",
    "!pip install git+https://github.com/awslabs/gluon-ts.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "from functools import partial\n",
    "\n",
    "# gluonts imports\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.distribution.piecewise_linear import PiecewiseLinearOutput\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "# gluonts models\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.4.dev79+g481fc5f\n"
     ]
    }
   ],
   "source": [
    "# gluonts version (important)\n",
    "import gluonts\n",
    "print(gluonts.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of series in m4 data: \n",
    "\n",
    "- Yearly: 23,000\n",
    "- Quarterly: 24,000\n",
    "- Monthly: 48,000\n",
    "- Weekly: 359\n",
    "- Daily: 4227\n",
    "- Hourly: 414\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m4_quarterly']\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    \"m4_yearly\",\n",
    "    \"m4_quarterly\"\n",
    "]\n",
    "\n",
    "print(datasets)\n",
    "\n",
    "epochs = 1\n",
    "num_batches_per_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n",
      "INFO:root:Using CPU\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    partial(\n",
    "        SimpleFeedForwardEstimator,\n",
    "        trainer=Trainer(\n",
    "            epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "        ),\n",
    "    ),\n",
    "    partial(\n",
    "        DeepAREstimator,\n",
    "        trainer=Trainer(\n",
    "            epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "        ),\n",
    "    ),\n",
    "    partial(\n",
    "        DeepAREstimator,\n",
    "        distr_output=PiecewiseLinearOutput(8),\n",
    "        trainer=Trainer(\n",
    "            epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "        ),\n",
    "    ),\n",
    "    partial(\n",
    "        MQCNNEstimator,\n",
    "        trainer=Trainer(\n",
    "            epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "        ),\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset_name, estimator):\n",
    "    dataset = get_dataset(dataset_name)\n",
    "    estimator = estimator(\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "        use_feat_static_cat=True,\n",
    "        cardinality=[\n",
    "            feat_static_cat.cardinality\n",
    "            for feat_static_cat in dataset.metadata.feat_static_cat\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(f\"evaluating {estimator} on {dataset}\")\n",
    "\n",
    "    predictor = estimator.train(dataset.train)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "\n",
    "    pprint.pprint(agg_metrics)\n",
    "\n",
    "    eval_dict = agg_metrics\n",
    "    eval_dict[\"dataset\"] = dataset_name\n",
    "    eval_dict[\"estimator\"] = type(estimator).__name__\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloading and processing m4_quarterly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<class 'gluonts.model.simple_feedforward._estimator.SimpleFeedForwardEstimator'>, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=1, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=50, patience=10, weight_decay=1e-08))\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_quarterly/train/data.json\n",
      "saving time-series into /home/ec2-user/.mxnet/gluon-ts/datasets/m4_quarterly/test/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_quarterly.\n",
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__() got an unexpected keyword argument 'use_feat_static_cat'\n",
      "functools.partial(<class 'gluonts.model.deepar._estimator.DeepAREstimator'>, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=1, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=50, patience=10, weight_decay=1e-08))\n",
      "evaluating gluonts.model.deepar._estimator.DeepAREstimator(cardinality=[24000], cell_type=\"lstm\", context_length=None, distr_output=gluonts.distribution.student_t.StudentTOutput(), dropout_rate=0.1, embedding_dimension=None, freq=\"3M\", lags_seq=None, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=8, scaling=True, time_features=None, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=1, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=50, patience=10, weight_decay=1e-08), use_feat_dynamic_real=False, use_feat_static_cat=True, use_feat_static_real=False) on TrainDatasets(metadata=<MetaData freq='3M' target=None feat_static_cat=[<CategoricalFeatureInfo name='feat_static_cat' cardinality='24000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=8>, train=<gluonts.dataset.common.FileDataset object at 0x7f35cfe98e48>, test=<gluonts.dataset.common.FileDataset object at 0x7f35cfc00ba8>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of parameters in DeepARTrainingNetwork: 1230523\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.02it/s, avg_epoch_loss=8.02]\n",
      "INFO:root:Epoch[0] Elapsed time 2.657 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=8.023245\n",
      "INFO:root:Loading parameters from best epoch (0)\n",
      "INFO:root:Final loss: 8.02324541091919 (occurred at epoch 0)\n",
      "INFO:root:End model training\n",
      "Running evaluation:  34%|███▍      | 8129/24000 [08:01<15:39, 16.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e1ba79ac7724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# catch exceptions that are happening during training to avoid failing the whole evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3fafd3c938a2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset_name, estimator)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     agg_metrics, item_metrics = Evaluator()(\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mts_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_series\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/evaluation/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ts_iterator, fcst_iterator, num_series)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Running evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         ) as it, np.errstate(invalid=\"ignore\"):\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_per_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dataset, num_eval_samples)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0moutput_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mnum_eval_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_eval_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         )\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/forecast_generator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inference_data_loader, prediction_net, input_names, freq, output_transform, num_eval_samples, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minference_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    results = []\n",
    "    for dataset_name in datasets:\n",
    "        for estimator in estimators:\n",
    "            print(estimator)\n",
    "            # catch exceptions that are happening during training to avoid failing the whole evaluation\n",
    "            try:\n",
    "                results.append(evaluate(dataset_name, estimator))\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sub_df = df[\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"estimator\",\n",
    "            \"RMSE\",\n",
    "            \"mean_wQuantileLoss\",\n",
    "            \"MASE\",\n",
    "            \"sMAPE\",\n",
    "            \"MSIS\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    print(sub_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"MASE\", \"sMAPE\", \"dataset\", \"estimator\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
