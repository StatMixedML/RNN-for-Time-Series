{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark m4\n",
    "\n",
    "How to fit several model and evaluate its predictions on three of subsets of M4 data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functools.partial\n",
    "\n",
    "Return a new `partial` object which when called will behave like *func* called with the positional arguments args and keyword arguments keywords. \n",
    "\n",
    "- [Source](https://docs.python.org/2/library/functools.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods  \n",
    "\n",
    "Brief overview of the used methods\n",
    "\n",
    "### `DeepAREstimator`\n",
    "\n",
    "- [`gluonts.model.deepar`](https://gluon-ts.mxnet.io/api/gluonts/gluonts.model.deepar.html)\n",
    "\n",
    "Construct a DeepAR estimator, implements an RNN-based model, close to the one described in\n",
    "\n",
    "- Salinas, David, Valentin Flunkert, and Jan Gasthaus. “DeepAR: Probabilistic forecasting with autoregressive recurrent networks.” arXiv preprint arXiv:1704.04110 (2017).\n",
    "\n",
    "\n",
    "### `MQCNNEstimator`\n",
    "\n",
    "- [`gluonts.model.seq2seq`](http://gluon-ts.mxnet.io/api/gluonts/gluonts.model.seq2seq.html)\n",
    "\n",
    "An `MQDNNEstimator` with Convolutional Neural Network (CNN) as an encoder. Implements the MQ-CNN Forecaster, proposed in \n",
    "\n",
    "- Wen, Ruofeng, et al. “A multi-horizon quantile recurrent forecaster.” arXiv preprint arXiv:1711.11053 (2017).\n",
    "\n",
    "\n",
    "### `SimpleFeedForwardEstimator`\n",
    "\n",
    "- [`gluonts.model.simple_feedforward`](http://gluon-ts.mxnet.io/api/gluonts/gluonts.model.simple_feedforward.html)\n",
    "\n",
    "A simple multilayer perceptron model predicting the next target time-steps given the previous ones. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/awslabs/gluon-ts.git\n",
      "  Cloning https://github.com/awslabs/gluon-ts.git to /tmp/pip-req-build-wsjwy6sf\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): gluonts==0.3.4.dev79+g481fc5f from git+https://github.com/awslabs/gluon-ts.git in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Requirement already satisfied: boto3==1.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (1.10.5)\n",
      "Requirement already satisfied: holidays==0.9.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (0.9.11)\n",
      "Requirement already satisfied: matplotlib==3.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (3.0.3)\n",
      "Requirement already satisfied: mxnet<1.5.*,>=1.4.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (1.4.1)\n",
      "Requirement already satisfied: numpy==1.14.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (1.14.5)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (0.25.3)\n",
      "Requirement already satisfied: pydantic==0.28.* in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (0.28)\n",
      "Requirement already satisfied: tqdm>=4.23.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (4.37.0)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluonts==0.3.4.dev79+g481fc5f) (1.35)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (1.13.5)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (0.9.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev79+g481fc5f) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from holidays==0.9.*->gluonts==0.3.4.dev79+g481fc5f) (2.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (2.2.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (0.8.4)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (2.20.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.25.0->gluonts==0.3.4.dev79+g481fc5f) (2018.4)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pydantic==0.28.*->gluonts==0.3.4.dev79+g481fc5f) (0.7)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.5->boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (1.23)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.5->boto3==1.*->gluonts==0.3.4.dev79+g481fc5f) (0.14)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.*->gluonts==0.3.4.dev79+g481fc5f) (39.1.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.20.0->mxnet<1.5.*,>=1.4.1->gluonts==0.3.4.dev79+g481fc5f) (2019.6.16)\n",
      "Building wheels for collected packages: gluonts\n",
      "  Running setup.py bdist_wheel for gluonts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-kue7zl_c/wheels/09/ba/b9/c830628df4d977a9dfe661f6001cdb861fc3f2524bac0ee433\n",
      "Successfully built gluonts\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install gluonts (most recent version)\n",
    "!pip install git+https://github.com/awslabs/gluon-ts.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "from functools import partial\n",
    "\n",
    "# gluonts imports\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.distribution.piecewise_linear import PiecewiseLinearOutput\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "# gluonts models\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.4.dev79+g481fc5f\n"
     ]
    }
   ],
   "source": [
    "# gluonts version (important)\n",
    "import gluonts\n",
    "print(gluonts.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of series in m4 data: \n",
    "\n",
    "- Yearly: 23,000\n",
    "- Quarterly: 24,000\n",
    "- Monthly: 48,000\n",
    "- Weekly: 359\n",
    "- Daily: 4227\n",
    "- Hourly: 414\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m4_quarterly', 'm4_yearly']\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "num_batches_per_epoch = 200\n",
    "\n",
    "datasets = [\n",
    "#     \"m4_hourly\",\n",
    "#     \"m4_daily\",\n",
    "#     \"m4_weekly\",\n",
    "#     \"m4_monthly\",\n",
    "    \"m4_quarterly\",\n",
    "    \"m4_yearly\",\n",
    "]\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using CPU\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "#     partial(\n",
    "#         SimpleFeedForwardEstimator,\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "    partial(\n",
    "        DeepAREstimator,\n",
    "        trainer=Trainer(\n",
    "            epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "        ),\n",
    "    ),\n",
    "#     partial(\n",
    "#         DeepAREstimator,\n",
    "#         distr_output=PiecewiseLinearOutput(8),\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "#     partial(\n",
    "#         MQCNNEstimator,\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset_name, estimator):\n",
    "    dataset = get_dataset(dataset_name)\n",
    "    estimator = estimator(\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "        use_feat_static_cat=True,\n",
    "        cardinality=[\n",
    "            feat_static_cat.cardinality\n",
    "            for feat_static_cat in dataset.metadata.feat_static_cat\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(f\"evaluating {estimator} on {dataset}\")\n",
    "\n",
    "    predictor = estimator.train(dataset.train)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "\n",
    "    pprint.pprint(agg_metrics)\n",
    "\n",
    "    eval_dict = agg_metrics\n",
    "    eval_dict[\"dataset\"] = dataset_name\n",
    "    eval_dict[\"estimator\"] = type(estimator).__name__\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m4_quarterly', 'm4_yearly']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_quarterly.\n",
      "INFO:root:Start model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<class 'gluonts.model.deepar._estimator.DeepAREstimator'>, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08))\n",
      "evaluating gluonts.model.deepar._estimator.DeepAREstimator(cardinality=[24000], cell_type=\"lstm\", context_length=None, distr_output=gluonts.distribution.student_t.StudentTOutput(), dropout_rate=0.1, embedding_dimension=None, freq=\"3M\", lags_seq=None, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=8, scaling=True, time_features=None, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08), use_feat_dynamic_real=False, use_feat_static_cat=True, use_feat_static_real=False) on TrainDatasets(metadata=<MetaData freq='3M' target=None feat_static_cat=[<CategoricalFeatureInfo name='feat_static_cat' cardinality='24000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=8>, train=<gluonts.dataset.common.FileDataset object at 0x7f35cf9c46d8>, test=<gluonts.dataset.common.FileDataset object at 0x7f35cfea9e80>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepARTrainingNetwork: 1230523\n",
      "100%|██████████| 200/200 [00:09<00:00, 20.00it/s, avg_epoch_loss=7.68]\n",
      "INFO:root:Epoch[0] Elapsed time 10.003 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=7.682601\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.36it/s, avg_epoch_loss=7.19]\n",
      "INFO:root:Epoch[1] Elapsed time 10.335 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=7.187988\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.90it/s, avg_epoch_loss=7.21]\n",
      "INFO:root:Epoch[2] Elapsed time 10.055 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=7.209194\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.17it/s, avg_epoch_loss=7.11]\n",
      "INFO:root:Epoch[3] Elapsed time 10.439 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=7.109260\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.66it/s, avg_epoch_loss=6.97]\n",
      "INFO:root:Epoch[4] Elapsed time 10.179 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=6.973633\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.90it/s, avg_epoch_loss=6.93]\n",
      "INFO:root:Epoch[5] Elapsed time 10.056 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=6.927042\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.50it/s, avg_epoch_loss=7.03]\n",
      "INFO:root:Epoch[6] Elapsed time 10.262 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=7.034608\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.46it/s, avg_epoch_loss=6.83]\n",
      "INFO:root:Epoch[7] Elapsed time 10.280 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=6.829085\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.92it/s, avg_epoch_loss=6.75]\n",
      "INFO:root:Epoch[8] Elapsed time 10.042 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=6.752450\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.52it/s, avg_epoch_loss=6.8]\n",
      "INFO:root:Epoch[9] Elapsed time 10.252 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=6.796861\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.55it/s, avg_epoch_loss=6.89]\n",
      "INFO:root:Epoch[10] Elapsed time 10.234 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=6.888084\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.57it/s, avg_epoch_loss=6.84]\n",
      "INFO:root:Epoch[11] Elapsed time 10.224 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=6.842079\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.45it/s, avg_epoch_loss=6.59]\n",
      "INFO:root:Epoch[12] Elapsed time 10.286 seconds\n",
      "INFO:root:Epoch[12] Evaluation metric 'epoch_loss'=6.586110\n",
      "INFO:root:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.99it/s, avg_epoch_loss=6.72]\n",
      "INFO:root:Epoch[13] Elapsed time 10.010 seconds\n",
      "INFO:root:Epoch[13] Evaluation metric 'epoch_loss'=6.723709\n",
      "INFO:root:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.86it/s, avg_epoch_loss=6.81]\n",
      "INFO:root:Epoch[14] Elapsed time 10.074 seconds\n",
      "INFO:root:Epoch[14] Evaluation metric 'epoch_loss'=6.806227\n",
      "INFO:root:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:09<00:00, 20.01it/s, avg_epoch_loss=6.7]\n",
      "INFO:root:Epoch[15] Elapsed time 10.003 seconds\n",
      "INFO:root:Epoch[15] Evaluation metric 'epoch_loss'=6.698924\n",
      "INFO:root:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.62it/s, avg_epoch_loss=6.59]\n",
      "INFO:root:Epoch[16] Elapsed time 10.198 seconds\n",
      "INFO:root:Epoch[16] Evaluation metric 'epoch_loss'=6.594262\n",
      "INFO:root:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.63it/s, avg_epoch_loss=6.77]\n",
      "INFO:root:Epoch[17] Elapsed time 10.193 seconds\n",
      "INFO:root:Epoch[17] Evaluation metric 'epoch_loss'=6.770883\n",
      "INFO:root:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.84it/s, avg_epoch_loss=6.58]\n",
      "INFO:root:Epoch[18] Elapsed time 10.085 seconds\n",
      "INFO:root:Epoch[18] Evaluation metric 'epoch_loss'=6.580357\n",
      "INFO:root:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.50it/s, avg_epoch_loss=6.56]\n",
      "INFO:root:Epoch[19] Elapsed time 10.265 seconds\n",
      "INFO:root:Epoch[19] Evaluation metric 'epoch_loss'=6.560579\n",
      "INFO:root:Epoch[20] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.82it/s, avg_epoch_loss=6.65]\n",
      "INFO:root:Epoch[20] Elapsed time 10.095 seconds\n",
      "INFO:root:Epoch[20] Evaluation metric 'epoch_loss'=6.649062\n",
      "INFO:root:Epoch[21] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.47it/s, avg_epoch_loss=6.62]\n",
      "INFO:root:Epoch[21] Elapsed time 10.275 seconds\n",
      "INFO:root:Epoch[21] Evaluation metric 'epoch_loss'=6.619976\n",
      "INFO:root:Epoch[22] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.79it/s, avg_epoch_loss=6.59]\n",
      "INFO:root:Epoch[22] Elapsed time 10.111 seconds\n",
      "INFO:root:Epoch[22] Evaluation metric 'epoch_loss'=6.585210\n",
      "INFO:root:Epoch[23] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.85it/s, avg_epoch_loss=6.55]\n",
      "INFO:root:Epoch[23] Elapsed time 10.082 seconds\n",
      "INFO:root:Epoch[23] Evaluation metric 'epoch_loss'=6.546905\n",
      "INFO:root:Epoch[24] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.46it/s, avg_epoch_loss=6.57]\n",
      "INFO:root:Epoch[24] Elapsed time 10.280 seconds\n",
      "INFO:root:Epoch[24] Evaluation metric 'epoch_loss'=6.567426\n",
      "INFO:root:Epoch[25] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.45it/s, avg_epoch_loss=6.62]\n",
      "INFO:root:Epoch[25] Elapsed time 10.286 seconds\n",
      "INFO:root:Epoch[25] Evaluation metric 'epoch_loss'=6.619973\n",
      "INFO:root:Epoch[26] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.45it/s, avg_epoch_loss=6.63]\n",
      "INFO:root:Epoch[26] Elapsed time 10.282 seconds\n",
      "INFO:root:Epoch[26] Evaluation metric 'epoch_loss'=6.628357\n",
      "INFO:root:Epoch[27] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.34it/s, avg_epoch_loss=6.47]\n",
      "INFO:root:Epoch[27] Elapsed time 10.345 seconds\n",
      "INFO:root:Epoch[27] Evaluation metric 'epoch_loss'=6.470410\n",
      "INFO:root:Epoch[28] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.99it/s, avg_epoch_loss=6.53]\n",
      "INFO:root:Epoch[28] Elapsed time 10.012 seconds\n",
      "INFO:root:Epoch[28] Evaluation metric 'epoch_loss'=6.526823\n",
      "INFO:root:Epoch[29] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.84it/s, avg_epoch_loss=6.63]\n",
      "INFO:root:Epoch[29] Elapsed time 10.081 seconds\n",
      "INFO:root:Epoch[29] Evaluation metric 'epoch_loss'=6.626486\n",
      "INFO:root:Epoch[30] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.92it/s, avg_epoch_loss=6.51]\n",
      "INFO:root:Epoch[30] Elapsed time 10.041 seconds\n",
      "INFO:root:Epoch[30] Evaluation metric 'epoch_loss'=6.513595\n",
      "INFO:root:Epoch[31] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.70it/s, avg_epoch_loss=6.47]\n",
      "INFO:root:Epoch[31] Elapsed time 10.160 seconds\n",
      "INFO:root:Epoch[31] Evaluation metric 'epoch_loss'=6.469526\n",
      "INFO:root:Epoch[32] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.57it/s, avg_epoch_loss=6.53]\n",
      "INFO:root:Epoch[32] Elapsed time 10.225 seconds\n",
      "INFO:root:Epoch[32] Evaluation metric 'epoch_loss'=6.530574\n",
      "INFO:root:Epoch[33] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.54it/s, avg_epoch_loss=6.51]\n",
      "INFO:root:Epoch[33] Elapsed time 10.242 seconds\n",
      "INFO:root:Epoch[33] Evaluation metric 'epoch_loss'=6.508474\n",
      "INFO:root:Epoch[34] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.57it/s, avg_epoch_loss=6.43]\n",
      "INFO:root:Epoch[34] Elapsed time 10.222 seconds\n",
      "INFO:root:Epoch[34] Evaluation metric 'epoch_loss'=6.429197\n",
      "INFO:root:Epoch[35] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.93it/s, avg_epoch_loss=6.58]\n",
      "INFO:root:Epoch[35] Elapsed time 10.039 seconds\n",
      "INFO:root:Epoch[35] Evaluation metric 'epoch_loss'=6.579213\n",
      "INFO:root:Epoch[36] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.97it/s, avg_epoch_loss=6.55]\n",
      "INFO:root:Epoch[36] Elapsed time 10.022 seconds\n",
      "INFO:root:Epoch[36] Evaluation metric 'epoch_loss'=6.551932\n",
      "INFO:root:Epoch[37] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.77it/s, avg_epoch_loss=6.49]\n",
      "INFO:root:Epoch[37] Elapsed time 10.120 seconds\n",
      "INFO:root:Epoch[37] Evaluation metric 'epoch_loss'=6.490725\n",
      "INFO:root:Epoch[38] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.65it/s, avg_epoch_loss=6.42]\n",
      "INFO:root:Epoch[38] Elapsed time 10.183 seconds\n",
      "INFO:root:Epoch[38] Evaluation metric 'epoch_loss'=6.421302\n",
      "INFO:root:Epoch[39] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.53it/s, avg_epoch_loss=6.45]\n",
      "INFO:root:Epoch[39] Elapsed time 10.245 seconds\n",
      "INFO:root:Epoch[39] Evaluation metric 'epoch_loss'=6.446824\n",
      "INFO:root:Epoch[40] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.57it/s, avg_epoch_loss=6.51]\n",
      "INFO:root:Epoch[40] Elapsed time 10.219 seconds\n",
      "INFO:root:Epoch[40] Evaluation metric 'epoch_loss'=6.507643\n",
      "INFO:root:Epoch[41] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.55it/s, avg_epoch_loss=6.54]\n",
      "INFO:root:Epoch[41] Elapsed time 10.235 seconds\n",
      "INFO:root:Epoch[41] Evaluation metric 'epoch_loss'=6.535846\n",
      "INFO:root:Epoch[42] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.52it/s, avg_epoch_loss=6.38]\n",
      "INFO:root:Epoch[42] Elapsed time 10.245 seconds\n",
      "INFO:root:Epoch[42] Evaluation metric 'epoch_loss'=6.377695\n",
      "INFO:root:Epoch[43] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:09<00:00, 20.04it/s, avg_epoch_loss=6.43]\n",
      "INFO:root:Epoch[43] Elapsed time 9.986 seconds\n",
      "INFO:root:Epoch[43] Evaluation metric 'epoch_loss'=6.429452\n",
      "INFO:root:Epoch[44] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.97it/s, avg_epoch_loss=6.51]\n",
      "INFO:root:Epoch[44] Elapsed time 10.022 seconds\n",
      "INFO:root:Epoch[44] Evaluation metric 'epoch_loss'=6.505376\n",
      "INFO:root:Epoch[45] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.95it/s, avg_epoch_loss=6.41]\n",
      "INFO:root:Epoch[45] Elapsed time 10.030 seconds\n",
      "INFO:root:Epoch[45] Evaluation metric 'epoch_loss'=6.412288\n",
      "INFO:root:Epoch[46] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.69it/s, avg_epoch_loss=6.4]\n",
      "INFO:root:Epoch[46] Elapsed time 10.161 seconds\n",
      "INFO:root:Epoch[46] Evaluation metric 'epoch_loss'=6.398296\n",
      "INFO:root:Epoch[47] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.97it/s, avg_epoch_loss=6.55]\n",
      "INFO:root:Epoch[47] Elapsed time 10.019 seconds\n",
      "INFO:root:Epoch[47] Evaluation metric 'epoch_loss'=6.553027\n",
      "INFO:root:Epoch[48] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.92it/s, avg_epoch_loss=6.41]\n",
      "INFO:root:Epoch[48] Elapsed time 10.047 seconds\n",
      "INFO:root:Epoch[48] Evaluation metric 'epoch_loss'=6.405255\n",
      "INFO:root:Epoch[49] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.90it/s, avg_epoch_loss=6.36]\n",
      "INFO:root:Epoch[49] Elapsed time 10.055 seconds\n",
      "INFO:root:Epoch[49] Evaluation metric 'epoch_loss'=6.363039\n",
      "INFO:root:Epoch[50] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.48it/s, avg_epoch_loss=6.51]\n",
      "INFO:root:Epoch[50] Elapsed time 10.275 seconds\n",
      "INFO:root:Epoch[50] Evaluation metric 'epoch_loss'=6.506357\n",
      "INFO:root:Epoch[51] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.59it/s, avg_epoch_loss=6.47]\n",
      "INFO:root:Epoch[51] Elapsed time 10.214 seconds\n",
      "INFO:root:Epoch[51] Evaluation metric 'epoch_loss'=6.468021\n",
      "INFO:root:Epoch[52] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.42it/s, avg_epoch_loss=6.41]\n",
      "INFO:root:Epoch[52] Elapsed time 10.303 seconds\n",
      "INFO:root:Epoch[52] Evaluation metric 'epoch_loss'=6.407087\n",
      "INFO:root:Epoch[53] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.63it/s, avg_epoch_loss=6.36]\n",
      "INFO:root:Epoch[53] Elapsed time 10.195 seconds\n",
      "INFO:root:Epoch[53] Evaluation metric 'epoch_loss'=6.356435\n",
      "INFO:root:Epoch[54] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.88it/s, avg_epoch_loss=6.42]\n",
      "INFO:root:Epoch[54] Elapsed time 10.067 seconds\n",
      "INFO:root:Epoch[54] Evaluation metric 'epoch_loss'=6.422620\n",
      "INFO:root:Epoch[55] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.89it/s, avg_epoch_loss=6.43]\n",
      "INFO:root:Epoch[55] Elapsed time 10.059 seconds\n",
      "INFO:root:Epoch[55] Evaluation metric 'epoch_loss'=6.426536\n",
      "INFO:root:Epoch[56] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.36it/s, avg_epoch_loss=6.45]\n",
      "INFO:root:Epoch[56] Elapsed time 10.338 seconds\n",
      "INFO:root:Epoch[56] Evaluation metric 'epoch_loss'=6.452291\n",
      "INFO:root:Epoch[57] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.91it/s, avg_epoch_loss=6.3]\n",
      "INFO:root:Epoch[57] Elapsed time 10.052 seconds\n",
      "INFO:root:Epoch[57] Evaluation metric 'epoch_loss'=6.300325\n",
      "INFO:root:Epoch[58] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.54it/s, avg_epoch_loss=6.32]\n",
      "INFO:root:Epoch[58] Elapsed time 10.238 seconds\n",
      "INFO:root:Epoch[58] Evaluation metric 'epoch_loss'=6.321413\n",
      "INFO:root:Epoch[59] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.46it/s, avg_epoch_loss=6.48]\n",
      "INFO:root:Epoch[59] Elapsed time 10.280 seconds\n",
      "INFO:root:Epoch[59] Evaluation metric 'epoch_loss'=6.475690\n",
      "INFO:root:Epoch[60] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.52it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[60] Elapsed time 10.251 seconds\n",
      "INFO:root:Epoch[60] Evaluation metric 'epoch_loss'=6.343816\n",
      "INFO:root:Epoch[61] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.45it/s, avg_epoch_loss=6.32]\n",
      "INFO:root:Epoch[61] Elapsed time 10.287 seconds\n",
      "INFO:root:Epoch[61] Evaluation metric 'epoch_loss'=6.319130\n",
      "INFO:root:Epoch[62] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.47it/s, avg_epoch_loss=6.42]\n",
      "INFO:root:Epoch[62] Elapsed time 10.273 seconds\n",
      "INFO:root:Epoch[62] Evaluation metric 'epoch_loss'=6.417865\n",
      "INFO:root:Epoch[63] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.50it/s, avg_epoch_loss=6.4] \n",
      "INFO:root:Epoch[63] Elapsed time 10.260 seconds\n",
      "INFO:root:Epoch[63] Evaluation metric 'epoch_loss'=6.395814\n",
      "INFO:root:Epoch[64] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.66it/s, avg_epoch_loss=6.37]\n",
      "INFO:root:Epoch[64] Elapsed time 10.173 seconds\n",
      "INFO:root:Epoch[64] Evaluation metric 'epoch_loss'=6.372032\n",
      "INFO:root:Epoch[65] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.40it/s, avg_epoch_loss=6.41]\n",
      "INFO:root:Epoch[65] Elapsed time 10.313 seconds\n",
      "INFO:root:Epoch[65] Evaluation metric 'epoch_loss'=6.410566\n",
      "INFO:root:Epoch[66] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.56it/s, avg_epoch_loss=6.33]\n",
      "INFO:root:Epoch[66] Elapsed time 10.229 seconds\n",
      "INFO:root:Epoch[66] Evaluation metric 'epoch_loss'=6.333855\n",
      "INFO:root:Epoch[67] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.40it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[67] Elapsed time 10.315 seconds\n",
      "INFO:root:Epoch[67] Evaluation metric 'epoch_loss'=6.338597\n",
      "INFO:root:Loading parameters from best epoch (57)\n",
      "INFO:root:Epoch[68] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.48it/s, avg_epoch_loss=6.29]\n",
      "INFO:root:Epoch[68] Elapsed time 10.272 seconds\n",
      "INFO:root:Epoch[68] Evaluation metric 'epoch_loss'=6.294152\n",
      "INFO:root:Epoch[69] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.93it/s, avg_epoch_loss=6.38]\n",
      "INFO:root:Epoch[69] Elapsed time 10.043 seconds\n",
      "INFO:root:Epoch[69] Evaluation metric 'epoch_loss'=6.376907\n",
      "INFO:root:Epoch[70] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.90it/s, avg_epoch_loss=6.41]\n",
      "INFO:root:Epoch[70] Elapsed time 10.057 seconds\n",
      "INFO:root:Epoch[70] Evaluation metric 'epoch_loss'=6.414799\n",
      "INFO:root:Epoch[71] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.67it/s, avg_epoch_loss=6.39]\n",
      "INFO:root:Epoch[71] Elapsed time 10.174 seconds\n",
      "INFO:root:Epoch[71] Evaluation metric 'epoch_loss'=6.385051\n",
      "INFO:root:Epoch[72] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.79it/s, avg_epoch_loss=6.24]\n",
      "INFO:root:Epoch[72] Elapsed time 10.111 seconds\n",
      "INFO:root:Epoch[72] Evaluation metric 'epoch_loss'=6.244341\n",
      "INFO:root:Epoch[73] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.53it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[73] Elapsed time 10.244 seconds\n",
      "INFO:root:Epoch[73] Evaluation metric 'epoch_loss'=6.338559\n",
      "INFO:root:Epoch[74] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 18.99it/s, avg_epoch_loss=6.41]\n",
      "INFO:root:Epoch[74] Elapsed time 10.536 seconds\n",
      "INFO:root:Epoch[74] Evaluation metric 'epoch_loss'=6.405519\n",
      "INFO:root:Epoch[75] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.53it/s, avg_epoch_loss=6.32]\n",
      "INFO:root:Epoch[75] Elapsed time 10.247 seconds\n",
      "INFO:root:Epoch[75] Evaluation metric 'epoch_loss'=6.321777\n",
      "INFO:root:Epoch[76] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.49it/s, avg_epoch_loss=6.26]\n",
      "INFO:root:Epoch[76] Elapsed time 10.269 seconds\n",
      "INFO:root:Epoch[76] Evaluation metric 'epoch_loss'=6.256646\n",
      "INFO:root:Epoch[77] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.56it/s, avg_epoch_loss=6.38]\n",
      "INFO:root:Epoch[77] Elapsed time 10.232 seconds\n",
      "INFO:root:Epoch[77] Evaluation metric 'epoch_loss'=6.381846\n",
      "INFO:root:Epoch[78] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.57it/s, avg_epoch_loss=6.31]\n",
      "INFO:root:Epoch[78] Elapsed time 10.224 seconds\n",
      "INFO:root:Epoch[78] Evaluation metric 'epoch_loss'=6.313673\n",
      "INFO:root:Epoch[79] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.62it/s, avg_epoch_loss=6.25]\n",
      "INFO:root:Epoch[79] Elapsed time 10.198 seconds\n",
      "INFO:root:Epoch[79] Evaluation metric 'epoch_loss'=6.252542\n",
      "INFO:root:Epoch[80] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.48it/s, avg_epoch_loss=6.37]\n",
      "INFO:root:Epoch[80] Elapsed time 10.272 seconds\n",
      "INFO:root:Epoch[80] Evaluation metric 'epoch_loss'=6.368862\n",
      "INFO:root:Epoch[81] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.60it/s, avg_epoch_loss=6.3]\n",
      "INFO:root:Epoch[81] Elapsed time 10.208 seconds\n",
      "INFO:root:Epoch[81] Evaluation metric 'epoch_loss'=6.297375\n",
      "INFO:root:Epoch[82] Learning rate is 0.0005\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.43it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[82] Elapsed time 10.297 seconds\n",
      "INFO:root:Epoch[82] Evaluation metric 'epoch_loss'=6.344004\n",
      "INFO:root:Loading parameters from best epoch (72)\n",
      "INFO:root:Epoch[83] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.53it/s, avg_epoch_loss=6.22]\n",
      "INFO:root:Epoch[83] Elapsed time 10.246 seconds\n",
      "INFO:root:Epoch[83] Evaluation metric 'epoch_loss'=6.223361\n",
      "INFO:root:Epoch[84] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.82it/s, avg_epoch_loss=6.35]\n",
      "INFO:root:Epoch[84] Elapsed time 10.095 seconds\n",
      "INFO:root:Epoch[84] Evaluation metric 'epoch_loss'=6.348315\n",
      "INFO:root:Epoch[85] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.93it/s, avg_epoch_loss=6.39]\n",
      "INFO:root:Epoch[85] Elapsed time 10.041 seconds\n",
      "INFO:root:Epoch[85] Evaluation metric 'epoch_loss'=6.389279\n",
      "INFO:root:Epoch[86] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.86it/s, avg_epoch_loss=6.33]\n",
      "INFO:root:Epoch[86] Elapsed time 10.073 seconds\n",
      "INFO:root:Epoch[86] Evaluation metric 'epoch_loss'=6.325641\n",
      "INFO:root:Epoch[87] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.94it/s, avg_epoch_loss=6.2]\n",
      "INFO:root:Epoch[87] Elapsed time 10.033 seconds\n",
      "INFO:root:Epoch[87] Evaluation metric 'epoch_loss'=6.199127\n",
      "INFO:root:Epoch[88] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.60it/s, avg_epoch_loss=6.29]\n",
      "INFO:root:Epoch[88] Elapsed time 10.209 seconds\n",
      "INFO:root:Epoch[88] Evaluation metric 'epoch_loss'=6.287003\n",
      "INFO:root:Epoch[89] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.39it/s, avg_epoch_loss=6.39]\n",
      "INFO:root:Epoch[89] Elapsed time 10.315 seconds\n",
      "INFO:root:Epoch[89] Evaluation metric 'epoch_loss'=6.394270\n",
      "INFO:root:Epoch[90] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.43it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[90] Elapsed time 10.297 seconds\n",
      "INFO:root:Epoch[90] Evaluation metric 'epoch_loss'=6.336367\n",
      "INFO:root:Epoch[91] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.00it/s, avg_epoch_loss=6.2] \n",
      "INFO:root:Epoch[91] Elapsed time 10.529 seconds\n",
      "INFO:root:Epoch[91] Evaluation metric 'epoch_loss'=6.199066\n",
      "INFO:root:Epoch[92] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.85it/s, avg_epoch_loss=6.33]\n",
      "INFO:root:Epoch[92] Elapsed time 10.077 seconds\n",
      "INFO:root:Epoch[92] Evaluation metric 'epoch_loss'=6.328186\n",
      "INFO:root:Epoch[93] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.86it/s, avg_epoch_loss=6.33]\n",
      "INFO:root:Epoch[93] Elapsed time 10.072 seconds\n",
      "INFO:root:Epoch[93] Evaluation metric 'epoch_loss'=6.327260\n",
      "INFO:root:Epoch[94] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.84it/s, avg_epoch_loss=6.25]\n",
      "INFO:root:Epoch[94] Elapsed time 10.085 seconds\n",
      "INFO:root:Epoch[94] Evaluation metric 'epoch_loss'=6.245600\n",
      "INFO:root:Epoch[95] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.69it/s, avg_epoch_loss=6.31]\n",
      "INFO:root:Epoch[95] Elapsed time 10.161 seconds\n",
      "INFO:root:Epoch[95] Evaluation metric 'epoch_loss'=6.309057\n",
      "INFO:root:Epoch[96] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.88it/s, avg_epoch_loss=6.31]\n",
      "INFO:root:Epoch[96] Elapsed time 10.066 seconds\n",
      "INFO:root:Epoch[96] Evaluation metric 'epoch_loss'=6.305526\n",
      "INFO:root:Epoch[97] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.71it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[97] Elapsed time 10.155 seconds\n",
      "INFO:root:Epoch[97] Evaluation metric 'epoch_loss'=6.340393\n",
      "INFO:root:Epoch[98] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.97it/s, avg_epoch_loss=6.19]\n",
      "INFO:root:Epoch[98] Elapsed time 10.020 seconds\n",
      "INFO:root:Epoch[98] Evaluation metric 'epoch_loss'=6.194770\n",
      "INFO:root:Epoch[99] Learning rate is 0.00025\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.50it/s, avg_epoch_loss=6.34]\n",
      "INFO:root:Epoch[99] Elapsed time 10.263 seconds\n",
      "INFO:root:Epoch[99] Evaluation metric 'epoch_loss'=6.335382\n",
      "INFO:root:Loading parameters from best epoch (98)\n",
      "INFO:root:Final loss: 6.194770045280457 (occurred at epoch 98)\n",
      "INFO:root:End model training\n",
      "Running evaluation: 100%|██████████| 24000/24000 [15:55<00:00, 25.12it/s]\n",
      "INFO:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_yearly.\n",
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]INFO:root:Number of parameters in DeepARTrainingNetwork: 1179723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coverage[0.1]': 0.12719791666666666,\n",
      " 'Coverage[0.2]': 0.23547916666666666,\n",
      " 'Coverage[0.3]': 0.3465625,\n",
      " 'Coverage[0.4]': 0.45766666666666667,\n",
      " 'Coverage[0.5]': 0.5669270833333333,\n",
      " 'Coverage[0.6]': 0.65740625,\n",
      " 'Coverage[0.7]': 0.7489479166666667,\n",
      " 'Coverage[0.8]': 0.8327239583333333,\n",
      " 'Coverage[0.9]': 0.90846875,\n",
      " 'MAE_Coverage': 0.042375578703703703,\n",
      " 'MASE': 1.1861513502573564,\n",
      " 'MSE': 1765542.6399753932,\n",
      " 'MSIS': 12.653754518857925,\n",
      " 'ND': 0.09403399785384435,\n",
      " 'NRMSE': 0.22240721468038516,\n",
      " 'QuantileLoss[0.1]': 49849717.43188706,\n",
      " 'QuantileLoss[0.2]': 75919951.68797913,\n",
      " 'QuantileLoss[0.3]': 93003162.64374237,\n",
      " 'QuantileLoss[0.4]': 103320982.27595215,\n",
      " 'QuantileLoss[0.5]': 107863960.7726059,\n",
      " 'QuantileLoss[0.6]': 106462717.99465942,\n",
      " 'QuantileLoss[0.7]': 99262580.98280334,\n",
      " 'QuantileLoss[0.8]': 84727111.27318114,\n",
      " 'QuantileLoss[0.9]': 59598954.38851623,\n",
      " 'RMSE': 1328.7372351128695,\n",
      " 'abs_error': 107863960.72151184,\n",
      " 'abs_target_mean': 5974.344119287491,\n",
      " 'abs_target_sum': 1147074070.9031982,\n",
      " 'mean_wQuantileLoss': 0.07555543653167662,\n",
      " 'sMAPE': 0.10125780993306437,\n",
      " 'seasonal_error': 473.4332698179725,\n",
      " 'wQuantileLoss[0.1]': 0.04345815034650355,\n",
      " 'wQuantileLoss[0.2]': 0.06618574476903683,\n",
      " 'wQuantileLoss[0.3]': 0.08107860250952435,\n",
      " 'wQuantileLoss[0.4]': 0.09007350518750538,\n",
      " 'wQuantileLoss[0.5]': 0.09403399789838729,\n",
      " 'wQuantileLoss[0.6]': 0.09281241786838701,\n",
      " 'wQuantileLoss[0.7]': 0.08653545878222552,\n",
      " 'wQuantileLoss[0.8]': 0.07386367927091891,\n",
      " 'wQuantileLoss[0.9]': 0.05195737215260077}\n",
      "functools.partial(<class 'gluonts.model.deepar._estimator.DeepAREstimator'>, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08))\n",
      "evaluating gluonts.model.deepar._estimator.DeepAREstimator(cardinality=[23000], cell_type=\"lstm\", context_length=None, distr_output=gluonts.distribution.student_t.StudentTOutput(), dropout_rate=0.1, embedding_dimension=None, freq=\"12M\", lags_seq=None, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=6, scaling=True, time_features=None, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08), use_feat_dynamic_real=False, use_feat_static_cat=True, use_feat_static_real=False) on TrainDatasets(metadata=<MetaData freq='12M' target=None feat_static_cat=[<CategoricalFeatureInfo name='feat_static_cat' cardinality='23000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=6>, train=<gluonts.dataset.common.FileDataset object at 0x7f35cf9cb470>, test=<gluonts.dataset.common.FileDataset object at 0x7f35cfea96a0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:08<00:00, 23.23it/s, avg_epoch_loss=7.5]\n",
      "INFO:root:Epoch[0] Elapsed time 8.617 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=7.502066\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 22.49it/s, avg_epoch_loss=7.04]\n",
      "INFO:root:Epoch[1] Elapsed time 8.895 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=7.040929\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:13<00:00, 14.70it/s, avg_epoch_loss=7.1] \n",
      "INFO:root:Epoch[2] Elapsed time 13.611 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=7.103089\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.78it/s, avg_epoch_loss=6.97]\n",
      "INFO:root:Epoch[3] Elapsed time 34.596 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=6.972173\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.09it/s, avg_epoch_loss=6.26]\n",
      "INFO:root:Epoch[4] Elapsed time 28.230 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=6.263177\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.14it/s, avg_epoch_loss=6.98]\n",
      "INFO:root:Epoch[5] Elapsed time 28.018 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=6.980565\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.03it/s, avg_epoch_loss=6.73]\n",
      "INFO:root:Epoch[6] Elapsed time 28.458 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=6.726639\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.14it/s, avg_epoch_loss=6.4] \n",
      "INFO:root:Epoch[7] Elapsed time 28.016 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=6.403168\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.05it/s, avg_epoch_loss=6.36]\n",
      "INFO:root:Epoch[8] Elapsed time 28.374 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=6.358804\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.79it/s, avg_epoch_loss=6.83]\n",
      "INFO:root:Epoch[9] Elapsed time 34.549 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=6.829343\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:22<00:00,  9.02it/s, avg_epoch_loss=6.66]\n",
      "INFO:root:Epoch[10] Elapsed time 22.200 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=6.659669\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 23.42it/s, avg_epoch_loss=6.05]\n",
      "INFO:root:Epoch[11] Elapsed time 8.545 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=6.054325\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 22.81it/s, avg_epoch_loss=6.72]\n",
      "INFO:root:Epoch[12] Elapsed time 8.772 seconds\n",
      "INFO:root:Epoch[12] Evaluation metric 'epoch_loss'=6.717213\n",
      "INFO:root:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 22.80it/s, avg_epoch_loss=6.58]\n",
      "INFO:root:Epoch[13] Elapsed time 8.777 seconds\n",
      "INFO:root:Epoch[13] Evaluation metric 'epoch_loss'=6.584944\n",
      "INFO:root:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 22.78it/s, avg_epoch_loss=6.43]\n",
      "INFO:root:Epoch[14] Elapsed time 8.783 seconds\n",
      "INFO:root:Epoch[14] Evaluation metric 'epoch_loss'=6.427369\n",
      "INFO:root:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 22.96it/s, avg_epoch_loss=6.03]\n",
      "INFO:root:Epoch[15] Elapsed time 8.716 seconds\n",
      "INFO:root:Epoch[15] Evaluation metric 'epoch_loss'=6.029108\n",
      "INFO:root:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:08<00:00, 23.61it/s, avg_epoch_loss=6.76]\n",
      "INFO:root:Epoch[16] Elapsed time 8.474 seconds\n",
      "INFO:root:Epoch[16] Evaluation metric 'epoch_loss'=6.756700\n",
      "INFO:root:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:10<00:00, 18.27it/s, avg_epoch_loss=6.5] \n",
      "INFO:root:Epoch[17] Elapsed time 10.954 seconds\n",
      "INFO:root:Epoch[17] Evaluation metric 'epoch_loss'=6.504646\n",
      "INFO:root:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.10it/s, avg_epoch_loss=6]   \n",
      "INFO:root:Epoch[18] Elapsed time 28.212 seconds\n",
      "INFO:root:Epoch[18] Evaluation metric 'epoch_loss'=5.999381\n",
      "INFO:root:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.02it/s, avg_epoch_loss=6.37]\n",
      "INFO:root:Epoch[19] Elapsed time 28.496 seconds\n",
      "INFO:root:Epoch[19] Evaluation metric 'epoch_loss'=6.368491\n",
      "INFO:root:Epoch[20] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.81it/s, avg_epoch_loss=6.55]\n",
      "INFO:root:Epoch[20] Elapsed time 34.426 seconds\n",
      "INFO:root:Epoch[20] Evaluation metric 'epoch_loss'=6.553001\n",
      "INFO:root:Epoch[21] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  6.98it/s, avg_epoch_loss=6.51]\n",
      "INFO:root:Epoch[21] Elapsed time 28.652 seconds\n",
      "INFO:root:Epoch[21] Evaluation metric 'epoch_loss'=6.511164\n",
      "INFO:root:Epoch[22] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.11it/s, avg_epoch_loss=5.9] \n",
      "INFO:root:Epoch[22] Elapsed time 28.142 seconds\n",
      "INFO:root:Epoch[22] Evaluation metric 'epoch_loss'=5.900340\n",
      "INFO:root:Epoch[23] Learning rate is 0.001\n",
      "100%|██████████| 200/200 [00:27<00:00,  7.16it/s, avg_epoch_loss=6.64]\n",
      "INFO:root:Epoch[23] Elapsed time 27.924 seconds\n",
      "INFO:root:Epoch[23] Evaluation metric 'epoch_loss'=6.642702\n",
      "INFO:root:Epoch[24] Learning rate is 0.001\n",
      " 35%|███▌      | 70/200 [00:12<00:23,  5.56it/s, avg_epoch_loss=6.25]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-3acff75b9608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# catch exceptions that are happening during training to avoid failing the whole evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-3fafd3c938a2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset_name, estimator)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"evaluating {estimator} on {dataset}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     forecast_it, ts_it = make_evaluation_predictions(\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hybrid_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input_names, train_iter)\u001b[0m\n\u001b[1;32m    258\u001b[0m                             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                             it.set_postfix(\n\u001b[1;32m    262\u001b[0m                                 ordered_dict={\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, _, preds)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inst\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    mx.random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    results = []\n",
    "    for dataset_name in datasets:\n",
    "        for estimator in estimators:\n",
    "            print(estimator)\n",
    "            # catch exceptions that are happening during training to avoid failing the whole evaluation\n",
    "            try:\n",
    "                results.append(evaluate(dataset_name, estimator))\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sub_df = df[\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"estimator\",\n",
    "            \"RMSE\",\n",
    "            \"mean_wQuantileLoss\",\n",
    "            \"MASE\",\n",
    "            \"sMAPE\",\n",
    "            \"MSIS\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    print(sub_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"dataset\", \"estimator\", \"MASE\", \"sMAPE\", \"MSIS\",\"wQuantileLoss[0.5]\", \"wQuantileLoss[0.9]\", ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
